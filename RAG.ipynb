{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAdbNxCPh9TkjDf8BIVwaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/RAG_project/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu transformers"
      ],
      "metadata": {
        "id": "QoiJXR-gztif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190707f3-b682-4cbc-ddd9-90914dd3d5d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM3Wsm4ooN2g",
        "outputId": "7bccc0b0-d52e-4fd5-e25a-f920778d9ff5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "aMSdWm-0n8Qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f18098e-7bbc-4fcf-d9b2-a138c72cf0d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.49 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.68.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.11-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m435.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.49-py3-none-any.whl (420 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.1/420.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.47\n",
            "    Uninstalling langchain-core-0.3.47:\n",
            "      Successfully uninstalled langchain-core-0.3.47\n",
            "Successfully installed langchain-core-0.3.49 langchain_openai-0.3.11 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "g4OVx76-lrhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3265ce-3ac2-46d0-f48a-ac59ccd8110c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.49)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install adjustText"
      ],
      "metadata": {
        "id": "y0K8IEW2z-6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0a94ac-687a-43ab-d76f-f0f1b9f65980"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-1.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from adjustText) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from adjustText) (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from adjustText) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.17.0)\n",
            "Downloading adjustText-1.3.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install mlflow\n",
        "\n",
        "!pip install faiss\n",
        "\n",
        "!pip install transformers sentence-transformers\n",
        "\n",
        "!pip install gitpython\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7cm8iin-V4e",
        "outputId": "0b17ef0e-99a6-46e1-9c7a-b61db37ed263"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.21.2-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.21.2 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.21.2-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.1)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.14.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.39)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.2->mlflow)\n",
            "  Downloading databricks_sdk-0.48.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.21.2->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (1.31.1)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.2->mlflow) (4.12.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.21.2->mlflow)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.2->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.2->mlflow)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.2->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.2->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.2->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.2->mlflow) (0.52b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.2->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.2->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.2->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.2->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.2->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.21.2->mlflow) (0.14.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.2->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.2->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.2->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.2->mlflow) (4.9)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.2->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.2->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.2->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.21.2-py3-none-any.whl (28.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.21.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.48.0-py3-none-any.whl (677 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.6/677.6 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, gunicorn, graphql-core, starlette, graphql-relay, docker, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed databricks-sdk-0.48.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.21.2 mlflow-skinny-2.21.2 starlette-0.46.1 uvicorn-0.34.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from transformers import AutoTokenizer, AutoModel, AutoTokenizer\n",
        "from langchain.vectorstores import FAISS\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from requests.adapters import HTTPAdapter, Retry\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import drive\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import json\n",
        "import random\n",
        "import umap\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from adjustText import adjust_text\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "from typing import List\n",
        "import mlflow\n",
        "from google.colab import userdata\n",
        "\n",
        "path = \"/content/drive/MyDrive/GitHubRepositoriesProject/\"\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AzOqW6QXWhZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c255a75-a381-4607-afb0-8a9876bfa151"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = pd.read_excel(\"/content/drive/MyDrive/GitHubRepositoriesProject/clean_df.xlsx\")"
      ],
      "metadata": {
        "id": "k9d86mKbjgWm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.shape"
      ],
      "metadata": {
        "id": "MyHqlB3bcey7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2f1d70-a9c8-4b1c-eb3d-c8bce2c6628e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11711, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "SjgipgROcFcX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the **CustomCodeBERTEmbeddings** Model  \n",
        "The **CodeBERT** model is designed for code-related data. It is based on **BERT** and trained with code data. This model allows generating representations of texts using a **tokenizer** and a **model**.  \n",
        "\n",
        "### The **embed_documents** Function  \n",
        "This function generates embeddings for each given text by:  \n",
        "- **Tokenization:** Breaking down the text into tokens.  \n",
        "- **Text Splitting:** Dividing texts based on length to fit the model’s input limit.  \n",
        "- **Batch Processing:** Producing embeddings in batches to improve efficiency."
      ],
      "metadata": {
        "id": "N-SA04qw1Ffh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.dropna(subset = 'Topics',inplace = True)\n",
        "clean_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-bU6geJBwtu",
        "outputId": "feac23e5-6750-479b-f2e1-c7d960aba774"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11699, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "2yxpLsoh-9Wv",
        "outputId": "b2cf7a35-0d29-4c83-b530-4bcad8ae1fcb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Name                                        Description  \\\n",
              "0              PyPOTS  toolboxlibrary data mining partially observed ...   \n",
              "1  changedetection.io  best simplest free open source website change ...   \n",
              "\n",
              "                                              URL          Created At  \\\n",
              "0              https://github.com/WenjieDu/PyPOTS 2022-03-29 14:22:47   \n",
              "1  https://github.com/dgtlmoon/changedetection.io 2021-01-27 16:03:30   \n",
              "\n",
              "           Updated At  Size  Stars  \\\n",
              "0 2023-09-25 04:20:18  7812    438   \n",
              "1 2023-09-21 11:00:40  6801  11908   \n",
              "\n",
              "                                              Topics  Overlap_Score  \\\n",
              "0  classification, clustering, data mining, forec...             37   \n",
              "1  back in stock, change alert, change detection,...             27   \n",
              "\n",
              "                                        Common_Words  Year  \n",
              "0  ['data', 'forecasting', 'incomplete', 'irregul...  2022  \n",
              "1  ['change', 'defacement', 'detection', 'monitor...  2021  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d51fe0a0-a568-4704-b49b-552e20c0b457\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "      <th>Created At</th>\n",
              "      <th>Updated At</th>\n",
              "      <th>Size</th>\n",
              "      <th>Stars</th>\n",
              "      <th>Topics</th>\n",
              "      <th>Overlap_Score</th>\n",
              "      <th>Common_Words</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PyPOTS</td>\n",
              "      <td>toolboxlibrary data mining partially observed ...</td>\n",
              "      <td>https://github.com/WenjieDu/PyPOTS</td>\n",
              "      <td>2022-03-29 14:22:47</td>\n",
              "      <td>2023-09-25 04:20:18</td>\n",
              "      <td>7812</td>\n",
              "      <td>438</td>\n",
              "      <td>classification, clustering, data mining, forec...</td>\n",
              "      <td>37</td>\n",
              "      <td>['data', 'forecasting', 'incomplete', 'irregul...</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>changedetection.io</td>\n",
              "      <td>best simplest free open source website change ...</td>\n",
              "      <td>https://github.com/dgtlmoon/changedetection.io</td>\n",
              "      <td>2021-01-27 16:03:30</td>\n",
              "      <td>2023-09-21 11:00:40</td>\n",
              "      <td>6801</td>\n",
              "      <td>11908</td>\n",
              "      <td>back in stock, change alert, change detection,...</td>\n",
              "      <td>27</td>\n",
              "      <td>['change', 'defacement', 'detection', 'monitor...</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d51fe0a0-a568-4704-b49b-552e20c0b457')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d51fe0a0-a568-4704-b49b-552e20c0b457 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d51fe0a0-a568-4704-b49b-552e20c0b457');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91dedb6d-e3c2-4cac-9a08-3a7a5eb5a71b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91dedb6d-e3c2-4cac-9a08-3a7a5eb5a71b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91dedb6d-e3c2-4cac-9a08-3a7a5eb5a71b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 11699,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11588,\n        \"samples\": [\n          \"beartype\",\n          \"hvcc\",\n          \"DeepTrade\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11610,\n        \"samples\": [\n          \"used deep automatic portrait matting pytorth\",\n          \"run evaluation llms human eval benchmark\",\n          \"mastering atari discrete world models\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11699,\n        \"samples\": [\n          \"https://github.com/fishaudio/fish-diffusion\",\n          \"https://github.com/shawnwun/NNDIAL\",\n          \"https://github.com/mniepert/mmkb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Created At\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2017-01-01 04:20:54\",\n        \"max\": \"2023-09-24 11:21:54\",\n        \"num_unique_values\": 11697,\n        \"samples\": [\n          \"2018-08-17 20:23:29\",\n          \"2020-01-25 12:47:02\",\n          \"2020-03-17 15:54:27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Updated At\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-02-19 18:27:20\",\n        \"max\": \"2023-09-25 19:23:47\",\n        \"num_unique_values\": 11566,\n        \"samples\": [\n          \"2023-09-20 11:07:48\",\n          \"2023-09-24 12:26:16\",\n          \"2023-09-16 21:04:14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 931585,\n        \"min\": 0,\n        \"max\": 93317358,\n        \"num_unique_values\": 7824,\n        \"samples\": [\n          9069,\n          79923,\n          879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3505,\n        \"min\": 167,\n        \"max\": 229569,\n        \"num_unique_values\": 2447,\n        \"samples\": [\n          12982,\n          522,\n          2059\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11554,\n        \"samples\": [\n          \"autoencoder, computer vision, deep learning, paper implementations, pytorch, representation learning, representations learning, slam, variational autoencoder, vision\",\n          \"artificial intelligence, attention mechanisms, audio synthesis, deep learning, transformers\",\n          \"digit, image processing, mathematics, pil, pillow, primality tests, prime numbers, sympy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overlap_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 37,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          18,\n          13,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Common_Words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8413,\n        \"samples\": [\n          \"['airflow', 'apache', 'dbt']\",\n          \"['data', 'extension', 'qlik', 'science', 'server']\",\n          \"['synthesis']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2017,\n        \"max\": 2023,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2022,\n          2021,\n          2020\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df[\"Topics\"].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "gP5WNQr0_XgT",
        "outputId": "51413897-92b9-415c-f8fd-3bb40c8b646b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    classification, clustering, data mining, forec...\n",
              "1    back in stock, change alert, change detection,...\n",
              "2    aco, ant colony optimization, artificial bee c...\n",
              "3    instagram, instagram api, instagram bot, insta...\n",
              "4    dashboard, log analysis, log parsing, scrapy, ...\n",
              "Name: Topics, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>classification, clustering, data mining, forec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>back in stock, change alert, change detection,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aco, ant colony optimization, artificial bee c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>instagram, instagram api, instagram bot, insta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dashboard, log analysis, log parsing, scrapy, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the Use Case  \n",
        "The use case involves **highly specific technical categories** (algorithm names, library names, tool descriptions, etc.).  \n",
        "\n",
        "### Why Simple Semantic Search Is Not Enough  \n",
        "- Simple embeddings may not accurately capture the precise meaning of technical terms.  \n",
        "- A model that understands technical terminology in depth is required (e.g., **CodeBERT**).  \n",
        "\n",
        "### Evaluation Approach  \n",
        "- Multiple indexes need to be evaluated to determine the most effective one.  \n",
        "- Using **MLFlow** will be ideal for tracking experiments and comparing results.  \n",
        "\n",
        "The plan is to build, test, and compare different index configurations to identify the most suitable setup for technical term retrieval.  \n",
        "\n",
        "Would you like me to proceed with the implementation of this approach?"
      ],
      "metadata": {
        "id": "dnsTQnU6AQZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling"
      ],
      "metadata": {
        "id": "JxM73IcBDdGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def radom_samplig(df):\n",
        "  return df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "sample_df = radom_samplig(clean_df)\n",
        "sample_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9S5RMzmDfBA",
        "outputId": "962b401c-8785-4e50-f0b1-b76d4a267e4d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1170, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "FwhtAiBxAzuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Models Overview  \n",
        "\n",
        "1. **CodeBERT**  \n",
        "   - Transformer-based model developed by Microsoft, trained on code-documentation pairs from public repositories.  \n",
        "   - **Strengths:** Excellent understanding of technical terms and code, ideal for topics related to programming languages, libraries, and algorithms.  \n",
        "   - **Source:** microsoft/codebert-base  \n",
        "\n",
        "2. **SciBERT**  \n",
        "   - Model by Allen Institute for AI, trained on scientific papers in computer science and biology.  \n",
        "   - **Strengths:** Excels in understanding technical and scientific texts, suitable for topics with academic or research-related terminology.  \n",
        "   - **Source:** allenai/scibert_scivocab_uncased  \n",
        "\n",
        "3. **OpenAI's GPT Embeddings (text-embedding-ada-002)**  \n",
        "   - Latest generation embedding model by OpenAI for high-quality general-purpose text embeddings.  \n",
        "   - **Strengths:** Provides deep semantic understanding, suitable for various topics but requires access to OpenAI's API.  \n",
        "   - **Source:** OpenAI API  "
      ],
      "metadata": {
        "id": "mkwW_fl_A5HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "hNShvRVgWLXR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_model_and_tokenizer(model_name, device):\n",
        "    \"\"\" Load model and tokenizer from HuggingFace. \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    return model, tokenizer\n",
        "\n",
        "def generate_embeddings_for_texts(texts, model, tokenizer, device):\n",
        "    \"\"\" Generate embeddings for a list of texts. \"\"\"\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            embedding = model(**inputs).last_hidden_state.mean(dim=1)  # Mean Pooling\n",
        "        embeddings.append(embedding.cpu().numpy().flatten())\n",
        "    return embeddings\n",
        "\n",
        "def generate_embeddings(df, embedding_type, batch_size=100, device=device, openai_api_key=userdata.get('open_ai_key')):\n",
        "\n",
        "    if openai_api_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key  # Set OpenAI API key if provided\n",
        "\n",
        "    # Load the correct embedding model\n",
        "    if embedding_type == \"GPT\":\n",
        "        embedding_model = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
        "    else:\n",
        "        model_name = \"microsoft/codebert-base\" if embedding_type == \"CodeBERT\" else \"allenai/scibert_scivocab_uncased\"\n",
        "        model, tokenizer = load_model_and_tokenizer(model_name, device)\n",
        "\n",
        "    embedding_col = f\"embedding_type_{embedding_type}\"\n",
        "        # Ensure any active MLFlow run is finished before starting a new one\n",
        "    if mlflow.active_run() is not None:\n",
        "        mlflow.end_run()\n",
        "\n",
        "    # Start new run for the visualization\n",
        "# Start new nested run\n",
        "    with mlflow.start_run(run_name=f\"Visualization - {embedding_col} - {index_type}\", nested=True):\n",
        "        mlflow.log_param(\"embedding_type\", embedding_col)\n",
        "        mlflow.log_param(\"index_type\", index_type)\n",
        "        mlflow.log_param(\"visualization_method\", method)\n",
        "\n",
        "\n",
        "        embeddings = []\n",
        "        topics_list = []\n",
        "\n",
        "        for topic in df[\"Topics\"]:\n",
        "            topics = \" \".join(topic) if isinstance(topic, list) else topic\n",
        "            topics_list.append(topics)\n",
        "\n",
        "        # Process in batches with tqdm\n",
        "        for i in tqdm(range(0, len(topics_list), batch_size), desc=f\"Generating Embeddings for {embedding_type}\", ncols=100):\n",
        "            batch = topics_list[i:i + batch_size]\n",
        "\n",
        "            if embedding_type == \"GPT\":\n",
        "                batch_embeddings = embedding_model.embed_documents(batch)\n",
        "            else:\n",
        "                batch_embeddings = generate_embeddings_for_texts(batch, model, tokenizer, device)\n",
        "\n",
        "            embeddings.extend(batch_embeddings)\n",
        "\n",
        "        mlflow.log_metric(\"num_documents\", len(embeddings))\n",
        "        df[embedding_col] = embeddings\n",
        "\n",
        "\n",
        "        output_file = f\"{embedding_type}_embeddings.xlsx\"\n",
        "        df.to_excel(output_file, index=False)\n",
        "        mlflow.log_artifact(output_file)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "qTEwEKfKA2MM",
        "outputId": "2e678bcf-7c32-48f5-8b92-585d26031ca8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 31)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    if mlflow.active_run() is not None:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for embedding_type in [\"CodeBERT\", \"SciBERT\", \"GPT\"]:\n",
        "    sample_df = generate_embeddings(sample_df, embedding_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdgCJKWfASDo",
        "outputId": "c338982a-95fd-4d2e-fbef-ace499552c5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings for CodeBERT: 100%|███████████████████████████| 12/12 [00:11<00:00,  1.08it/s]\n",
            "Generating Embeddings for SciBERT:   0%|                                     | 0/12 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Generating Embeddings for SciBERT: 100%|████████████████████████████| 12/12 [00:10<00:00,  1.13it/s]\n",
            "Generating Embeddings for GPT: 100%|████████████████████████████████| 12/12 [00:13<00:00,  1.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "cI0JkI12PE2x",
        "outputId": "6a8d7605-5513-443b-9d86-deb4094b9d05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Name                                        Description  \\\n",
              "11513  fish-diffusion              easy understand tts svs svc framework   \n",
              "2087           NNDIAL  nndial open source toolkit building end end tr...   \n",
              "11323            mmkb                                data modalities kbs   \n",
              "\n",
              "                                               URL          Created At  \\\n",
              "11513  https://github.com/fishaudio/fish-diffusion 2023-01-09 11:01:24   \n",
              "2087            https://github.com/shawnwun/NNDIAL 2017-05-26 14:38:00   \n",
              "11323             https://github.com/mniepert/mmkb 2018-02-21 12:33:24   \n",
              "\n",
              "               Updated At   Size  Stars  \\\n",
              "11513 2023-09-24 01:44:44  64316    458   \n",
              "2087  2023-09-01 08:40:42  73976    346   \n",
              "11323 2023-09-18 04:12:17  34709    314   \n",
              "\n",
              "                                                  Topics  Overlap_Score  \\\n",
              "11513                 diffusion, pytorch, soundgenerator              0   \n",
              "2087   dialogue, dialogue agents, dialogue generation...              6   \n",
              "11323                          freebase, knowledge graph              0   \n",
              "\n",
              "                  Common_Words  Year  \\\n",
              "11513                       []  2023   \n",
              "2087   ['dialogue', 'systems']  2017   \n",
              "11323                       []  2018   \n",
              "\n",
              "                                 embedding_type_CodeBERT  \\\n",
              "11513  [-0.17904958, 0.025005545, 0.43965673, 0.22487...   \n",
              "2087   [-0.23475327, 0.05144652, 0.24216096, 0.262912...   \n",
              "11323  [-0.035101186, 0.24884412, -0.0036410564, 0.21...   \n",
              "\n",
              "                                  embedding_type_SciBERT  \\\n",
              "11513  [0.053714093, 0.085433334, 0.29141527, 1.08931...   \n",
              "2087   [0.24996585, 0.52364385, 1.1472524, 0.16191079...   \n",
              "11323  [-0.37098655, 0.6352393, 0.012849961, 0.187038...   \n",
              "\n",
              "                                      embedding_type_GPT  \n",
              "11513  [-0.022421832212293664, -0.010774396815080795,...  \n",
              "2087   [-0.019818763283536413, -0.004093711464014754,...  \n",
              "11323  [0.02163246698806835, -0.007554954566117445, -...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2b73b77-fe27-4881-af47-5040241d813d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "      <th>Created At</th>\n",
              "      <th>Updated At</th>\n",
              "      <th>Size</th>\n",
              "      <th>Stars</th>\n",
              "      <th>Topics</th>\n",
              "      <th>Overlap_Score</th>\n",
              "      <th>Common_Words</th>\n",
              "      <th>Year</th>\n",
              "      <th>embedding_type_CodeBERT</th>\n",
              "      <th>embedding_type_SciBERT</th>\n",
              "      <th>embedding_type_GPT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11513</th>\n",
              "      <td>fish-diffusion</td>\n",
              "      <td>easy understand tts svs svc framework</td>\n",
              "      <td>https://github.com/fishaudio/fish-diffusion</td>\n",
              "      <td>2023-01-09 11:01:24</td>\n",
              "      <td>2023-09-24 01:44:44</td>\n",
              "      <td>64316</td>\n",
              "      <td>458</td>\n",
              "      <td>diffusion, pytorch, soundgenerator</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>2023</td>\n",
              "      <td>[-0.17904958, 0.025005545, 0.43965673, 0.22487...</td>\n",
              "      <td>[0.053714093, 0.085433334, 0.29141527, 1.08931...</td>\n",
              "      <td>[-0.022421832212293664, -0.010774396815080795,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2087</th>\n",
              "      <td>NNDIAL</td>\n",
              "      <td>nndial open source toolkit building end end tr...</td>\n",
              "      <td>https://github.com/shawnwun/NNDIAL</td>\n",
              "      <td>2017-05-26 14:38:00</td>\n",
              "      <td>2023-09-01 08:40:42</td>\n",
              "      <td>73976</td>\n",
              "      <td>346</td>\n",
              "      <td>dialogue, dialogue agents, dialogue generation...</td>\n",
              "      <td>6</td>\n",
              "      <td>['dialogue', 'systems']</td>\n",
              "      <td>2017</td>\n",
              "      <td>[-0.23475327, 0.05144652, 0.24216096, 0.262912...</td>\n",
              "      <td>[0.24996585, 0.52364385, 1.1472524, 0.16191079...</td>\n",
              "      <td>[-0.019818763283536413, -0.004093711464014754,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11323</th>\n",
              "      <td>mmkb</td>\n",
              "      <td>data modalities kbs</td>\n",
              "      <td>https://github.com/mniepert/mmkb</td>\n",
              "      <td>2018-02-21 12:33:24</td>\n",
              "      <td>2023-09-18 04:12:17</td>\n",
              "      <td>34709</td>\n",
              "      <td>314</td>\n",
              "      <td>freebase, knowledge graph</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>2018</td>\n",
              "      <td>[-0.035101186, 0.24884412, -0.0036410564, 0.21...</td>\n",
              "      <td>[-0.37098655, 0.6352393, 0.012849961, 0.187038...</td>\n",
              "      <td>[0.02163246698806835, -0.007554954566117445, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b73b77-fe27-4881-af47-5040241d813d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2b73b77-fe27-4881-af47-5040241d813d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2b73b77-fe27-4881-af47-5040241d813d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2dcf6c77-47e9-4626-b85f-362e3a64d86a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dcf6c77-47e9-4626-b85f-362e3a64d86a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2dcf6c77-47e9-4626-b85f-362e3a64d86a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample_df",
              "summary": "{\n  \"name\": \"sample_df\",\n  \"rows\": 1170,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1166,\n        \"samples\": [\n          \"FCOS\",\n          \"awesome-dash\",\n          \"seglearn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1163,\n        \"samples\": [\n          \"realtime web apps dashboards r\",\n          \"defence metric learning speaker recognition\",\n          \"derived climate climate xarray\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1170,\n        \"samples\": [\n          \"https://github.com/KaiyangZhou/pytorch-vsumm-reinforce\",\n          \"https://github.com/Raptor123471/DingoLingo\",\n          \"https://github.com/lewangdev/youtube-drive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Created At\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2017-01-04 00:25:05\",\n        \"max\": \"2023-09-20 15:19:38\",\n        \"num_unique_values\": 1170,\n        \"samples\": [\n          \"2018-04-19 16:36:11\",\n          \"2020-08-12 03:33:20\",\n          \"2022-05-26 15:47:32\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Updated At\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-02-12 01:51:31\",\n        \"max\": \"2023-09-25 18:17:38\",\n        \"num_unique_values\": 1167,\n        \"samples\": [\n          \"2023-09-15 21:50:04\",\n          \"2023-09-20 02:34:52\",\n          \"2023-09-25 07:33:28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2831292,\n        \"min\": 4,\n        \"max\": 93317358,\n        \"num_unique_values\": 1069,\n        \"samples\": [\n          19,\n          892,\n          1609\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2537,\n        \"min\": 167,\n        \"max\": 36446,\n        \"num_unique_values\": 668,\n        \"samples\": [\n          5139,\n          342,\n          1064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1168,\n        \"samples\": [\n          \"bbc news, cnn, fox news, google news, newsapi, top headlines news\",\n          \"chatbot, deep learning, deeplearning, korean, korean chatbot, sentence classification, sequance tagging, web crawler\",\n          \"bugbounty, mobile security, reverse engineering, ssl pinning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overlap_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 37,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0,\n          13,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Common_Words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 970,\n        \"samples\": [\n          \"['performance']\",\n          \"['imessage']\",\n          \"['engine', 'search']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2017,\n        \"max\": 2023,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2023,\n          2017,\n          2021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding_type_CodeBERT\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding_type_SciBERT\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding_type_GPT\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index vactors"
      ],
      "metadata": {
        "id": "YJ8iYdmTRwco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **IndexFlatL2**  \n",
        "Description: A simple index that performs exact searches by calculating Euclidean distance (L2) between vectors.  \n",
        "Advantages: Provides fully accurate results.  \n",
        "Disadvantages: Slow and inefficient for large datasets.  \n",
        "Recommended Use: Best for small datasets when accuracy is the top priority.  \n",
        "\n",
        "2. **IndexIVFPQ (Inverted File with Product Quantization)**  \n",
        "Description: Combines inverted files with product quantization to reduce computations and speed up searches.  \n",
        "Advantages: Fast searches on large datasets with reduced memory usage.  \n",
        "Disadvantages: Requires training; accuracy depends on parameters like nlist (number of clusters) and nprobe (number of probes).  \n",
        "Recommended Use: Suitable for large datasets where speed is important, with some accuracy compromise.  \n",
        "\n",
        "3. **IndexHNSW (Hierarchical Navigable Small World)**  \n",
        "Description: Graph-based index enabling efficient approximate searches with sub-linear time complexity.  \n",
        "Advantages: Good balance between speed and accuracy; ideal for approximate searches.  \n",
        "Disadvantages: High memory consumption; doesn't support adding vectors with custom IDs.  \n",
        "Recommended Use: Best when search speed is crucial, even if it slightly affects accuracy.  "
      ],
      "metadata": {
        "id": "fM6yq6_2R0O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_faiss_index(embeddings, index_type, nlist=100, nprobe=10, ef_search=200):\n",
        "\n",
        "    embeddings = np.array(embeddings).astype('float32')\n",
        "    dim = embeddings.shape[1]\n",
        "\n",
        "    with mlflow.start_run(run_name=f\"Index Creation - {index_type}\"):\n",
        "        mlflow.log_param(\"index_type\", index_type)\n",
        "        mlflow.log_param(\"embedding_dimension\", dim)\n",
        "\n",
        "        if index_type == 'FlatL2':\n",
        "            index = faiss.IndexFlatL2(dim)\n",
        "            mlflow.log_param(\"index_method\", \"FlatL2\")\n",
        "\n",
        "        elif index_type == 'IVFPQ':\n",
        "            quantizer = faiss.IndexFlatL2(dim)\n",
        "            index = faiss.IndexIVFPQ(quantizer, dim, nlist, 8, 8)\n",
        "            index.train(embeddings)\n",
        "            index.nprobe = nprobe\n",
        "\n",
        "            mlflow.log_param(\"index_method\", \"IVFPQ\")\n",
        "            mlflow.log_param(\"nlist\", nlist)\n",
        "            mlflow.log_param(\"nprobe\", nprobe)\n",
        "\n",
        "        elif index_type == 'HNSW':\n",
        "            index = faiss.IndexHNSWFlat(dim, 32)\n",
        "            index.hnsw.efSearch = ef_search\n",
        "\n",
        "            mlflow.log_param(\"index_method\", \"HNSW\")\n",
        "            mlflow.log_param(\"ef_search\", ef_search)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported index type: {index_type}\")\n",
        "\n",
        "        index.add(embeddings)\n",
        "        mlflow.log_metric(\"number_of_vectors\", len(embeddings))\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "def save_index(index, file_path):\n",
        "    faiss.write_index(index, file_path)\n",
        "\n",
        "\n",
        "def load_index(file_path):\n",
        "    return faiss.read_index(file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "ts3bwINlR07O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_indices(df, embedding_columns, index_types, output_folder):\n",
        "    \"\"\"\n",
        "    Create and save all index combinations for given embeddings and index types.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for embedding_col in embedding_columns:\n",
        "        embeddings = np.array(df[embedding_col].tolist()).astype('float32')\n",
        "        for index_type in index_types:\n",
        "            index = create_faiss_index(embeddings, index_type)\n",
        "\n",
        "            # Save index with a meaningful name\n",
        "            file_name = f\"{embedding_col}_{index_type}.index\"\n",
        "            file_path = os.path.join(output_folder, file_name)\n",
        "            save_index(index, file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "TTPBWVt5ASGG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_columns = ['embedding_type_CodeBERT', 'embedding_type_SciBERT', 'embedding_type_GPT']\n",
        "index_types = ['FlatL2', 'IVFPQ', 'HNSW']\n",
        "process_all_indices(sample_df, embedding_columns, index_types, output_folder=\"indexes\")"
      ],
      "metadata": {
        "id": "URN-tV50ASIk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "4xyGL66npRWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import mlflow\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from umap import UMAP\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def visualize_embeddings(embeddings, labels=None, method=\"UMAP\", title=\"\", save_path=None, show_plot=True):\n",
        "    \"\"\"Visualizes the embeddings with clustering labels.\"\"\"\n",
        "    if method == \"UMAP\":\n",
        "        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
        "    elif method == \"t-SNE\":\n",
        "        reducer = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported visualization method. Use 'UMAP' or 't-SNE'.\")\n",
        "\n",
        "    reduced_embeddings = reducer.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    if labels is not None:\n",
        "        unique_labels = np.unique(labels)\n",
        "        palette = sns.color_palette(\"hsv\", len(unique_labels))\n",
        "        sns.scatterplot(x=reduced_embeddings[:, 0], y=reduced_embeddings[:, 1], hue=labels, palette=palette, s=100, legend=\"full\")\n",
        "    else:\n",
        "        sns.scatterplot(x=reduced_embeddings[:, 0], y=reduced_embeddings[:, 1], s=10)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    return reduced_embeddings\n",
        "\n",
        "\n",
        "def analyze_embeddings(embeddings, labels):\n",
        "    \"\"\"Analyze the clustering quality using silhouette score and Davies-Bouldin Index.\"\"\"\n",
        "    metrics = {}\n",
        "    metrics['Silhouette_Score'] = silhouette_score(embeddings, labels)\n",
        "    metrics['Davies_Bouldin_Index'] = davies_bouldin_score(embeddings, labels)\n",
        "\n",
        "    print(f\"\\nClustering Metrics:\\nSilhouette Score: {metrics['Silhouette_Score']:.4f}\")\n",
        "    print(f\"Davies-Bouldin Index: {metrics['Davies_Bouldin_Index']:.4f}\\n\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def perform_clustering(embeddings, method=\"KMeans\", num_clusters=5):\n",
        "    \"\"\"Perform clustering using the specified method.\"\"\"\n",
        "    if method == \"KMeans\":\n",
        "        clusterer = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "        labels = clusterer.fit_predict(embeddings)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported clustering method. Use 'KMeans' only.\")\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def visualize_all_combinations_with_clustering(df, embedding_columns, index_types, method=\"UMAP\", output_folder=\"plots\"):\n",
        "    \"\"\"Visualizes and clusters all combinations of embeddings and indices.\"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for idx, embedding_col in enumerate(embedding_columns):\n",
        "        embeddings = np.array(df[embedding_col].tolist()).astype('float32')\n",
        "\n",
        "        for index_type in index_types:\n",
        "            with mlflow.start_run(run_name=f\"Visualization - {embedding_col} - {index_type}\"):\n",
        "\n",
        "                mlflow.log_param(\"embedding_type\", embedding_col)\n",
        "                mlflow.log_param(\"index_type\", index_type)\n",
        "                mlflow.log_param(\"visualization_method\", method)\n",
        "\n",
        "                # Visualize embeddings without clustering labels first\n",
        "                reduced_embeddings = visualize_embeddings(embeddings, method=method, title=f\"{embedding_col} - {index_type} - Raw\", show_plot=False)\n",
        "\n",
        "                # Perform KMeans clustering\n",
        "                labels = perform_clustering(reduced_embeddings, method=\"KMeans\")\n",
        "\n",
        "                # Analyze the clustering metrics\n",
        "                metrics = analyze_embeddings(reduced_embeddings, labels)\n",
        "\n",
        "                # Log metrics in MLFlow\n",
        "                mlflow.log_metrics(metrics)\n",
        "\n",
        "                # Plot and save the visualization with clusters\n",
        "                plot_title = f\"{embedding_col} - {index_type} - KMeans\"\n",
        "                plot_file = os.path.join(output_folder, f\"{plot_title}.png\")\n",
        "                visualize_embeddings(reduced_embeddings, labels=labels, method=method, title=plot_title, save_path=plot_file, show_plot=True)\n",
        "\n",
        "                # Store results\n",
        "                results.append({\n",
        "                    'Embedding': embedding_col,\n",
        "                    'Index_Type': index_type,\n",
        "                    'Cluster': labels[idx],\n",
        "                    'Silhouette_Score': metrics['Silhouette_Score'],\n",
        "                    'Davies_Bouldin_Index': metrics['Davies_Bouldin_Index']\n",
        "                })\n",
        "\n",
        "    # Save results as a DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_file = os.path.join(output_folder, \"clustering_results.xlsx\")\n",
        "    results_df.to_excel(results_file, index=False)\n",
        "    mlflow.log_artifact(results_file)\n",
        "    print(f\"\\nAll results saved to: {results_file}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "embedding_columns = ['embedding_type_CodeBERT', 'embedding_type_SciBERT', 'embedding_type_GPT']\n",
        "index_types = ['FlatL2', 'IVFPQ', 'HNSW']\n",
        "results_df = visualize_all_combinations_with_clustering(sample_df, embedding_columns, index_types, method=\"UMAP\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEBTqqfyASKw",
        "outputId": "42526f8d-acfc-4c43-c2ff-4eb410c96d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6iwzmPGTRzv3",
        "outputId": "37d51665-d1d5-426a-91fd-7a5c4a8a8f65"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Embedding Index_Type  Clustering_Labels  Silhouette_Score  \\\n",
              "0   embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "1   embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "2   embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "3   embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "4   embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "5   embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "6   embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "7   embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "8   embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "9   embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "10  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "11  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "12  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "13  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "14  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "15  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "16  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "17  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "18  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "19  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "20  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "21  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "22  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "23  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "24  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "25  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "26  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "27  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "28  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "29  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "30  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "31  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "32  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "33  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "34  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "35  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "36  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "37  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "38  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "39  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "40  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "41  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "42  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "43  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "44  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "45  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "46  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "47  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "48  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "49  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "50  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "51  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "52  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "53  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "54  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "55  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "56  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "57  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "58  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "59  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "60  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "61  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "62  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "63  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "64  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "65  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "66  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "67  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "68  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "69  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "70  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "71  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "72  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "73  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "74  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "75  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "76  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "77  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "78  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "79  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "80  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "81  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "82  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "83  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "84  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "85  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "86  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "87  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "88  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "89  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "90  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "91  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "92  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "93  embedding_type_CodeBERT     FlatL2                  1          0.410102   \n",
              "94  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "95  embedding_type_CodeBERT     FlatL2                  2          0.410102   \n",
              "96  embedding_type_CodeBERT     FlatL2                  3          0.410102   \n",
              "97  embedding_type_CodeBERT     FlatL2                  4          0.410102   \n",
              "98  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "99  embedding_type_CodeBERT     FlatL2                  0          0.410102   \n",
              "\n",
              "    Davies_Bouldin_Index  \n",
              "0               0.773073  \n",
              "1               0.773073  \n",
              "2               0.773073  \n",
              "3               0.773073  \n",
              "4               0.773073  \n",
              "5               0.773073  \n",
              "6               0.773073  \n",
              "7               0.773073  \n",
              "8               0.773073  \n",
              "9               0.773073  \n",
              "10              0.773073  \n",
              "11              0.773073  \n",
              "12              0.773073  \n",
              "13              0.773073  \n",
              "14              0.773073  \n",
              "15              0.773073  \n",
              "16              0.773073  \n",
              "17              0.773073  \n",
              "18              0.773073  \n",
              "19              0.773073  \n",
              "20              0.773073  \n",
              "21              0.773073  \n",
              "22              0.773073  \n",
              "23              0.773073  \n",
              "24              0.773073  \n",
              "25              0.773073  \n",
              "26              0.773073  \n",
              "27              0.773073  \n",
              "28              0.773073  \n",
              "29              0.773073  \n",
              "30              0.773073  \n",
              "31              0.773073  \n",
              "32              0.773073  \n",
              "33              0.773073  \n",
              "34              0.773073  \n",
              "35              0.773073  \n",
              "36              0.773073  \n",
              "37              0.773073  \n",
              "38              0.773073  \n",
              "39              0.773073  \n",
              "40              0.773073  \n",
              "41              0.773073  \n",
              "42              0.773073  \n",
              "43              0.773073  \n",
              "44              0.773073  \n",
              "45              0.773073  \n",
              "46              0.773073  \n",
              "47              0.773073  \n",
              "48              0.773073  \n",
              "49              0.773073  \n",
              "50              0.773073  \n",
              "51              0.773073  \n",
              "52              0.773073  \n",
              "53              0.773073  \n",
              "54              0.773073  \n",
              "55              0.773073  \n",
              "56              0.773073  \n",
              "57              0.773073  \n",
              "58              0.773073  \n",
              "59              0.773073  \n",
              "60              0.773073  \n",
              "61              0.773073  \n",
              "62              0.773073  \n",
              "63              0.773073  \n",
              "64              0.773073  \n",
              "65              0.773073  \n",
              "66              0.773073  \n",
              "67              0.773073  \n",
              "68              0.773073  \n",
              "69              0.773073  \n",
              "70              0.773073  \n",
              "71              0.773073  \n",
              "72              0.773073  \n",
              "73              0.773073  \n",
              "74              0.773073  \n",
              "75              0.773073  \n",
              "76              0.773073  \n",
              "77              0.773073  \n",
              "78              0.773073  \n",
              "79              0.773073  \n",
              "80              0.773073  \n",
              "81              0.773073  \n",
              "82              0.773073  \n",
              "83              0.773073  \n",
              "84              0.773073  \n",
              "85              0.773073  \n",
              "86              0.773073  \n",
              "87              0.773073  \n",
              "88              0.773073  \n",
              "89              0.773073  \n",
              "90              0.773073  \n",
              "91              0.773073  \n",
              "92              0.773073  \n",
              "93              0.773073  \n",
              "94              0.773073  \n",
              "95              0.773073  \n",
              "96              0.773073  \n",
              "97              0.773073  \n",
              "98              0.773073  \n",
              "99              0.773073  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85d52db1-2a04-4e73-a845-ede26fbdfbb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Embedding</th>\n",
              "      <th>Index_Type</th>\n",
              "      <th>Clustering_Labels</th>\n",
              "      <th>Silhouette_Score</th>\n",
              "      <th>Davies_Bouldin_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>embedding_type_CodeBERT</td>\n",
              "      <td>FlatL2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410102</td>\n",
              "      <td>0.773073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85d52db1-2a04-4e73-a845-ede26fbdfbb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85d52db1-2a04-4e73-a845-ede26fbdfbb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85d52db1-2a04-4e73-a845-ede26fbdfbb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-871187df-d200-40c0-9eb1-0eeaabc1cb38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-871187df-d200-40c0-9eb1-0eeaabc1cb38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-871187df-d200-40c0-9eb1-0eeaabc1cb38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 10530,\n  \"fields\": [\n    {\n      \"column\": \"Embedding\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"embedding_type_CodeBERT\",\n          \"embedding_type_SciBERT\",\n          \"embedding_type_GPT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Index_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FlatL2\",\n          \"IVFPQ\",\n          \"HNSW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clustering_Labels\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Silhouette_Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.41010159254074097,\n          0.3925442099571228,\n          0.4595014452934265\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Davies_Bouldin_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08943616417018758,\n        \"min\": 0.7212449860296364,\n        \"max\": 0.9314867949168161,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.773073380481755,\n          0.9314867949168161,\n          0.7212449860296364\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_labels.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "_kNNrG7azMTS",
        "outputId": "7b27eada-f2f2-4f9d-f0c1-338adde16ed2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Name                                        Description  \\\n",
              "11513  fish-diffusion              easy understand tts svs svc framework   \n",
              "2087           NNDIAL  nndial open source toolkit building end end tr...   \n",
              "\n",
              "                                               URL          Created At  \\\n",
              "11513  https://github.com/fishaudio/fish-diffusion 2023-01-09 11:01:24   \n",
              "2087            https://github.com/shawnwun/NNDIAL 2017-05-26 14:38:00   \n",
              "\n",
              "               Updated At   Size  Stars  \\\n",
              "11513 2023-09-24 01:44:44  64316    458   \n",
              "2087  2023-09-01 08:40:42  73976    346   \n",
              "\n",
              "                                                  Topics  Overlap_Score  \\\n",
              "11513                 diffusion, pytorch, soundgenerator              0   \n",
              "2087   dialogue, dialogue agents, dialogue generation...              6   \n",
              "\n",
              "                  Common_Words  Year  \\\n",
              "11513                       []  2023   \n",
              "2087   ['dialogue', 'systems']  2017   \n",
              "\n",
              "                                 embedding_type_CodeBERT  \\\n",
              "11513  [-0.17904958, 0.025005545, 0.43965673, 0.22487...   \n",
              "2087   [-0.23475327, 0.05144652, 0.24216096, 0.262912...   \n",
              "\n",
              "                                  embedding_type_SciBERT  \\\n",
              "11513  [0.053714093, 0.085433334, 0.29141527, 1.08931...   \n",
              "2087   [0.24996585, 0.52364385, 1.1472524, 0.16191079...   \n",
              "\n",
              "                                      embedding_type_GPT  \\\n",
              "11513  [-0.022421832212293664, -0.010774396815080795,...   \n",
              "2087   [-0.019818763283536413, -0.004093711464014754,...   \n",
              "\n",
              "       embedding_type_CodeBERT_FlatL2_labels  \\\n",
              "11513                                      3   \n",
              "2087                                       4   \n",
              "\n",
              "       embedding_type_CodeBERT_IVFPQ_labels  \\\n",
              "11513                                     3   \n",
              "2087                                      4   \n",
              "\n",
              "       embedding_type_CodeBERT_HNSW_labels  \\\n",
              "11513                                    3   \n",
              "2087                                     4   \n",
              "\n",
              "       embedding_type_SciBERT_FlatL2_labels  \\\n",
              "11513                                     2   \n",
              "2087                                      1   \n",
              "\n",
              "       embedding_type_SciBERT_IVFPQ_labels  \\\n",
              "11513                                    2   \n",
              "2087                                     1   \n",
              "\n",
              "       embedding_type_SciBERT_HNSW_labels  embedding_type_GPT_FlatL2_labels  \\\n",
              "11513                                   2                                 1   \n",
              "2087                                    1                                 1   \n",
              "\n",
              "       embedding_type_GPT_IVFPQ_labels  embedding_type_GPT_HNSW_labels  \n",
              "11513                                1                               1  \n",
              "2087                                 1                               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a33fc322-06b3-47a1-b2ca-8336bb28b1d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "      <th>Created At</th>\n",
              "      <th>Updated At</th>\n",
              "      <th>Size</th>\n",
              "      <th>Stars</th>\n",
              "      <th>Topics</th>\n",
              "      <th>Overlap_Score</th>\n",
              "      <th>Common_Words</th>\n",
              "      <th>Year</th>\n",
              "      <th>embedding_type_CodeBERT</th>\n",
              "      <th>embedding_type_SciBERT</th>\n",
              "      <th>embedding_type_GPT</th>\n",
              "      <th>embedding_type_CodeBERT_FlatL2_labels</th>\n",
              "      <th>embedding_type_CodeBERT_IVFPQ_labels</th>\n",
              "      <th>embedding_type_CodeBERT_HNSW_labels</th>\n",
              "      <th>embedding_type_SciBERT_FlatL2_labels</th>\n",
              "      <th>embedding_type_SciBERT_IVFPQ_labels</th>\n",
              "      <th>embedding_type_SciBERT_HNSW_labels</th>\n",
              "      <th>embedding_type_GPT_FlatL2_labels</th>\n",
              "      <th>embedding_type_GPT_IVFPQ_labels</th>\n",
              "      <th>embedding_type_GPT_HNSW_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11513</th>\n",
              "      <td>fish-diffusion</td>\n",
              "      <td>easy understand tts svs svc framework</td>\n",
              "      <td>https://github.com/fishaudio/fish-diffusion</td>\n",
              "      <td>2023-01-09 11:01:24</td>\n",
              "      <td>2023-09-24 01:44:44</td>\n",
              "      <td>64316</td>\n",
              "      <td>458</td>\n",
              "      <td>diffusion, pytorch, soundgenerator</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>2023</td>\n",
              "      <td>[-0.17904958, 0.025005545, 0.43965673, 0.22487...</td>\n",
              "      <td>[0.053714093, 0.085433334, 0.29141527, 1.08931...</td>\n",
              "      <td>[-0.022421832212293664, -0.010774396815080795,...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2087</th>\n",
              "      <td>NNDIAL</td>\n",
              "      <td>nndial open source toolkit building end end tr...</td>\n",
              "      <td>https://github.com/shawnwun/NNDIAL</td>\n",
              "      <td>2017-05-26 14:38:00</td>\n",
              "      <td>2023-09-01 08:40:42</td>\n",
              "      <td>73976</td>\n",
              "      <td>346</td>\n",
              "      <td>dialogue, dialogue agents, dialogue generation...</td>\n",
              "      <td>6</td>\n",
              "      <td>['dialogue', 'systems']</td>\n",
              "      <td>2017</td>\n",
              "      <td>[-0.23475327, 0.05144652, 0.24216096, 0.262912...</td>\n",
              "      <td>[0.24996585, 0.52364385, 1.1472524, 0.16191079...</td>\n",
              "      <td>[-0.019818763283536413, -0.004093711464014754,...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a33fc322-06b3-47a1-b2ca-8336bb28b1d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a33fc322-06b3-47a1-b2ca-8336bb28b1d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a33fc322-06b3-47a1-b2ca-8336bb28b1d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4eede55e-361b-47b2-8ef1-adc05a99be3d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4eede55e-361b-47b2-8ef1-adc05a99be3d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4eede55e-361b-47b2-8ef1-adc05a99be3d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_with_labels"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "def get_tfidf_top_words_for_cluster(cluster_topics, top_n=5):\n",
        "    \"\"\"Get the top N distinguishing words for a given cluster using TF-IDF.\"\"\"\n",
        "    # Initialize TF-IDF vectorizer\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    # Create the TF-IDF matrix for all topics in the cluster\n",
        "    tfidf_matrix = vectorizer.fit_transform(cluster_topics)\n",
        "\n",
        "    # Get the words corresponding to the columns of the TF-IDF matrix\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Sum TF-IDF scores for each word across all documents in the cluster\n",
        "    tfidf_scores = np.asarray(tfidf_matrix.sum(axis=0)).flatten()\n",
        "\n",
        "    # Get the top N words with the highest TF-IDF scores\n",
        "    top_words_idx = tfidf_scores.argsort()[-top_n:][::-1]\n",
        "    top_words = feature_names[top_words_idx]\n",
        "\n",
        "    return top_words\n",
        "\n",
        "# Example usage within the clustering context:\n",
        "def visualize_embeddings_with_tfidf(embeddings, labels, topics, method=\"UMAP\", title=\"\", save_path=None, show_plot=True):\n",
        "    \"\"\"Visualizes the embeddings with clustering labels and top TF-IDF words.\"\"\"\n",
        "    reduced_embeddings = visualize_embeddings(embeddings, labels, method=method, title=title, save_path=save_path, show_plot=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # Plot the clusters with color based on their labels\n",
        "    sns.scatterplot(x=reduced_embeddings[:, 0], y=reduced_embeddings[:, 1], hue=labels, palette=\"Set2\", s=100, alpha=0.7, edgecolor='k')\n",
        "    plt.title(title)\n",
        "\n",
        "    # Display the top words for each cluster using TF-IDF\n",
        "    for cluster in np.unique(labels):\n",
        "        cluster_indices = [i for i, label in enumerate(labels) if label == cluster]\n",
        "        cluster_topics = [topics[i] for i in cluster_indices]\n",
        "\n",
        "        # Get the most distinguishing words for the cluster\n",
        "        top_words = get_tfidf_top_words_for_cluster(cluster_topics)\n",
        "\n",
        "        # Display top words near each cluster\n",
        "        for word, pos in zip(top_words, reduced_embeddings[labels == cluster][:5]):\n",
        "            plt.text(pos[0], pos[1], word, color=\"black\", fontsize=9, ha='center')\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    return reduced_embeddings\n"
      ],
      "metadata": {
        "id": "hETq4eN6ASRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3nFf8o8JAST5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNyOg2HWASV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNehLNvpASYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnpw5Ss_ASal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gu_ySOInAScx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7EIgO35lASfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZNfpnYZAShc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jqbI_LfASjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCodeBERTEmbeddings(Embeddings):\n",
        "    def __init__(self, model_name=\"microsoft/codebert-base\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "    def embed_documents(self, texts, batch_size=64):  # הוספנו batch_size כארגומנט\n",
        "        embeddings = []\n",
        "\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i + batch_size]\n",
        "            inputs = self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "\n",
        "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # שימוש ב-CLS Token\n",
        "            embeddings.extend(batch_embeddings)\n",
        "\n",
        "        return np.array(embeddings)\n",
        "\n",
        "    def embed_query(self, query):\n",
        "        return self.embed_documents([query])[0]\n",
        "\n",
        "embeddings = CustomCodeBERTEmbeddings()\n",
        "\n"
      ],
      "metadata": {
        "id": "_nR5tq08WUlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation  \n",
        "At this stage, the program prepares **all_tokens** and **index_mapping**, allowing me to track which tokens belong to each position in the data.  \n",
        "\n",
        "Then, the **embed_documents** function is used to generate embeddings for the tokens. Each embedding is stored as a vector, and the information is saved in a dictionary called **vector_to_repo** to link each embedding to its original location in the data."
      ],
      "metadata": {
        "id": "A0l4n2zX1QbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors, vector_to_repo = [], {}\n",
        "current_index = 0\n",
        "batch_size = 64\n",
        "\n",
        "# הכנת רשימות שמכילות את כל ה-Tokens מתוך ה-DataFrame\n",
        "all_tokens, index_mapping = [], []\n",
        "for index, topic in tqdm(enumerate(clean_df[\"Topics\"]), total=len(clean_df), desc=\"Extracting Tokens\"):\n",
        "    if not(isinstance(topic, str) and len(topic.strip()) > 0): continue\n",
        "    tokens = [token.strip() for token in topic.split(\",\") if token.strip()]\n",
        "    all_tokens.extend(tokens)\n",
        "    index_mapping.extend([index] * len(tokens))\n",
        "\n",
        "# יצירת האימבדינגס בצורה יעילה עם Batching\n",
        "all_vectors = embeddings.embed_documents(all_tokens, batch_size=batch_size)\n",
        "\n",
        "# שמירת המידע במילון כדי שנוכל לחזור למיקום המקורי בדאטה\n",
        "for i, vector in enumerate(all_vectors):\n",
        "    vector_to_repo[i] = index_mapping[i]\n",
        "\n",
        "# המרת הוקטורים למערך NumPy\n",
        "all_vectors = np.array(all_vectors, dtype='float32')\n"
      ],
      "metadata": {
        "id": "YNBu7zWDYNA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Indexes with FAISS  \n",
        "**FAISS** is a tool optimized for vector-based searches. At this stage, the system creates an **Index** for each different **nlist** group.  \n",
        "\n",
        "Different indexes are built to allow efficient storage and searching over all the generated embeddings.  \n",
        "\n",
        "A new index is constructed for each **nlist**, which is periodically evaluated through searches to select the optimal values."
      ],
      "metadata": {
        "id": "q397P6sl1VUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_optimized_faiss_indexes(all_vectors, nlist_values):\n",
        "    \"\"\"\n",
        "    Creating Different Indexes with FAISS for Various nlist Values\n",
        "    \"\"\"\n",
        "    d = all_vectors.shape[1]\n",
        "    indexes = {}\n",
        "\n",
        "    for nlist in nlist_values:\n",
        "        quantizer = faiss.IndexFlatIP(d)\n",
        "        index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "        index.train(all_vectors)\n",
        "        index.add(all_vectors)\n",
        "\n",
        "        indexes[nlist] = index\n",
        "        # print(f\"\\n Created FAISS index with nlist={nlist}. Number of embeddings indexed: {index.ntotal}\")\n",
        "\n",
        "    return indexes\n",
        "\n",
        "\n",
        "nlist_values = [100, 200, 300, 500]\n",
        "indexes = create_optimized_faiss_indexes(all_vectors, nlist_values)\n"
      ],
      "metadata": {
        "id": "hyP03PpkcUMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Searching with FAISS  \n",
        "At this stage, the search is performed within the created indexes. A user query is provided (e.g., \"deep learning\"), and the model searches for the most similar results by comparing embeddings.  \n",
        "\n",
        "The **search_in_index** function searches for the closest words to the query and returns the results along with the words, topics, and relevant links."
      ],
      "metadata": {
        "id": "L5b3EjRz1eKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def search_in_index(query: str, index, top_k: int = 10, nprobe: int = 10):\n",
        "#     \"\"\"\n",
        "#     Advanced Search with FAISS using IndexIVFFlat\n",
        "#     \"\"\"\n",
        "#     index.nprobe = nprobe\n",
        "#     query_vector = embeddings.embed_query(query)\n",
        "\n",
        "#     start_time = time.time()  # מדידת זמן ריצה\n",
        "#     distances, indices = index.search(np.array([query_vector], dtype='float32'), top_k)\n",
        "#     end_time = time.time()\n",
        "\n",
        "#     results = []\n",
        "#     for i, idx in enumerate(indices[0]):\n",
        "#         if idx == -1:\n",
        "#             continue\n",
        "\n",
        "#         repo_index = vector_to_repo[idx]\n",
        "#         repo_name = clean_df.iloc[repo_index][\"Name\"]\n",
        "#         repo_url = clean_df.iloc[repo_index][\"URL\"]\n",
        "#         repo_topics = clean_df.iloc[repo_index][\"Topics\"]\n",
        "#         score = distances[0][i]\n",
        "\n",
        "#         results.append({\n",
        "#             \"name\": repo_name,\n",
        "#             \"url\": repo_url,\n",
        "#             \"topics\": repo_topics,\n",
        "#             \"score\": score\n",
        "#         })\n",
        "\n",
        "#     search_time = end_time - start_time\n",
        "#     return results, search_time\n"
      ],
      "metadata": {
        "id": "6sCmP0jOYpsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search  \n",
        "To maximize system performance, a **Grid Search** is performed where different parameter values, such as **nlist** and **nprobe**, are tested.  \n",
        "\n",
        "This process allows me to evaluate search time, the number of relevant results, and filter the results optimally."
      ],
      "metadata": {
        "id": "rpyAN_nC1mpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def grid_search_faiss(queries, indexes, nprobe_values, top_k=10):\n",
        "#     \"\"\"\n",
        "#     Performing Searches for All Combinations of nlist and nprobe\n",
        "#     \"\"\"\n",
        "#     results_summary = []\n",
        "\n",
        "#     for nlist, index in indexes.items():\n",
        "#         for nprobe in nprobe_values:\n",
        "#             for query in queries:\n",
        "#                 search_results, search_time = search_in_index(query, index, top_k=top_k, nprobe=nprobe)\n",
        "\n",
        "\n",
        "#                 found_projects = [result['name'] for result in search_results]\n",
        "#                 found_topics = [result['topics'] for result in search_results]\n",
        "#                 found_urls = [result['url'] for result in search_results]\n",
        "#                 found_scores = [result['score'] for result in search_results]\n",
        "\n",
        "\n",
        "#                 results_summary.append({\n",
        "#                     \"query\": query,\n",
        "#                     \"nlist\": nlist,\n",
        "#                     \"nprobe\": nprobe,\n",
        "#                     \"top_k\": top_k,\n",
        "#                     \"search_time\": search_time,\n",
        "#                     \"relevant_results\": len(found_projects),\n",
        "#                     \"found_projects\": found_projects,\n",
        "#                     \"found_topics\": found_topics,\n",
        "#                     \"found_urls\": found_urls,\n",
        "#                     \"found_scores\": found_scores\n",
        "\n",
        "#                 })\n",
        "\n",
        "\n",
        "#     results_df = pd.DataFrame(results_summary)\n",
        "#     return results_df\n"
      ],
      "metadata": {
        "id": "cOOQkGfzpmsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queries = [\"deep learning\", \"neural networks\", \"python libraries\", \"computer vision\", \"natural language processing\"]\n",
        "# nprobe_values = [10, 20, 30, 50]\n",
        "\n",
        "# results_df = grid_search_faiss(queries, indexes, nprobe_values, top_k=10)"
      ],
      "metadata": {
        "id": "CJg6Wqyypocf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results_df.T"
      ],
      "metadata": {
        "id": "1DIjb2QuquhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results_df.to_excel(\"/content/drive/MyDrive/GitHubRepositoriesProject/results_df.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "LXtv-IOQ3Xam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81wyNNH7pmYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/GitHubRepositoriesProject/\"\n",
        "\n",
        "def save_parameters(all_vectors, vector_to_repo, all_tokens, indexes, embeddings):\n",
        "    \"\"\"\n",
        "    Save all the required data to disk.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path + \"saved_data\"):\n",
        "        os.makedirs(path + \"saved_data\")\n",
        "\n",
        "    # Save embeddings and vector_to_repo\n",
        "    with open(path + \"saved_data/embeddings_data.pkl\", \"wb\") as f:\n",
        "        pickle.dump({\n",
        "            \"all_vectors\": all_vectors,\n",
        "            \"vector_to_repo\": vector_to_repo,\n",
        "            \"all_tokens\": all_tokens,\n",
        "            \"embeddings_name\": embeddings.model.config.name_or_path  # Save model name instead of the object\n",
        "        }, f)\n",
        "\n",
        "    # Save FAISS indexes\n",
        "    for nlist, index in indexes.items():\n",
        "        faiss.write_index(index, path + f\"saved_data/faiss_index_{nlist}.index\")\n",
        "\n",
        "    print(\"All data has been successfully saved.\")\n",
        "\n",
        "save_parameters(all_vectors, vector_to_repo, all_tokens, indexes, embeddings)\n"
      ],
      "metadata": {
        "id": "l6xOlwnHHy-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering\n"
      ],
      "metadata": {
        "id": "ZzUvLmrKwFUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MiniBatch KNN"
      ],
      "metadata": {
        "id": "kvMoWCO3wLLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from adjustText import adjust_text\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# ---- 1. הפחתת ממדים בעזרת UMAP ----\n",
        "def reduce_with_umap(all_vectors, n_neighbors=30, min_dist=0.1, n_components=2):\n",
        "    umap_reducer = umap.UMAP(\n",
        "        n_neighbors=n_neighbors,\n",
        "        min_dist=min_dist,\n",
        "        n_components=n_components,\n",
        "        metric='cosine',\n",
        "        random_state=42\n",
        "    )\n",
        "    reduced_embeddings = umap_reducer.fit_transform(all_vectors)\n",
        "    return reduced_embeddings"
      ],
      "metadata": {
        "id": "Y56ryD4QwIFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ---- 2. ביצוע MiniBatch KMeans ----\n",
        "def run_mini_batch_kmeans(reduced_embeddings, n_clusters=20):\n",
        "    kmeans = MiniBatchKMeans(\n",
        "        n_clusters=n_clusters,\n",
        "        batch_size=1000,\n",
        "        random_state=42,\n",
        "        max_iter=300\n",
        "    )\n",
        "    labels = kmeans.fit_predict(reduced_embeddings)\n",
        "    return labels, kmeans\n",
        "\n",
        "# ---- 3. הצגת תוצאות על גרף ----\n",
        "def plot_clusters_with_words(reduced_embeddings, labels, all_tokens, title='MiniBatch KMeans Clustering'):\n",
        "    embedding_df = pd.DataFrame({\n",
        "        'UMAP1': reduced_embeddings[:, 0],\n",
        "        'UMAP2': reduced_embeddings[:, 1],\n",
        "        'Token': all_tokens,\n",
        "        'Cluster': labels\n",
        "    })\n",
        "\n",
        "    # ---- חישוב תדירות מילות מפתח ----\n",
        "    token_frequency = embedding_df['Token'].value_counts()\n",
        "    embedding_df['Frequency'] = embedding_df['Token'].map(token_frequency)\n",
        "\n",
        "    # ---- סינון מונחים לפי שכיחותם ----\n",
        "    threshold_frequency = 5  # הצגת מונחים שמופיעים לפחות מספר פעמים זה\n",
        "    filtered_df = embedding_df[embedding_df['Frequency'] >= threshold_frequency]\n",
        "\n",
        "    # ---- נירמול התדירות בין 0 ל-1 ----\n",
        "    scaler = MinMaxScaler()\n",
        "    embedding_df['Frequency_Scaled'] = scaler.fit_transform(embedding_df[['Frequency']])\n",
        "\n",
        "    # ---- הצגת גרף ----\n",
        "    plt.figure(figsize=(18, 12))\n",
        "    sns.scatterplot(\n",
        "        data=embedding_df,\n",
        "        x='UMAP1', y='UMAP2',\n",
        "        hue='Cluster',\n",
        "        palette='tab20',\n",
        "        legend='full',\n",
        "        alpha=0.6\n",
        "    )\n",
        "\n",
        "    previous_tokens = set()  # רשימה לשמירה על המילים שכבר הוצגו\n",
        "    texts = []  # רשימה של הטקסטים שמוסיפים לגרף\n",
        "\n",
        "    # הוספת טקסטים למרכזי קלאסטרים\n",
        "    for cluster_label in embedding_df['Cluster'].unique():\n",
        "        cluster_df = filtered_df[filtered_df['Cluster'] == cluster_label]\n",
        "\n",
        "        # סידור לפי תדירות המילים בתוך כל קלאסטר\n",
        "        top_words = cluster_df.groupby('Token')['Frequency'].sum().sort_values(ascending=False)\n",
        "\n",
        "        # בחירת מילה הכי שכיחה שאינה חופפת למילים שכבר הודפסו\n",
        "        for token, freq in top_words.items():\n",
        "            cluster_center = cluster_df[['UMAP1', 'UMAP2']].mean()\n",
        "            if token not in previous_tokens:\n",
        "                texts.append(plt.text(\n",
        "                    cluster_center['UMAP1'],\n",
        "                    cluster_center['UMAP2'],\n",
        "                    token,\n",
        "                    fontsize=min(20, 8 + freq / 2),\n",
        "                    alpha=0.9,\n",
        "                    weight='bold' if freq > 50 else 'normal'\n",
        "                ))\n",
        "                previous_tokens.add(token)\n",
        "                break  # לקחת רק את המילה הכי שכיחה לקלאסטר\n",
        "\n",
        "    # התאמת המילים מבלי לחפוף אחת על השנייה\n",
        "    adjust_text(texts)\n",
        "\n",
        "    plt.title(title, fontsize=22)\n",
        "    plt.xlabel('UMAP Dimension 1', fontsize=16)\n",
        "    plt.ylabel('UMAP Dimension 2', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    return embedding_df\n",
        "\n",
        "\n",
        "# ---- 4. הפחתת ממדים עם כל האימבדינגס ----\n",
        "reduced_embeddings = reduce_with_umap(all_vectors)\n",
        "\n",
        "# ---- 5. קלאסטרינג מלא על כל האימבדינגס ----\n",
        "labels, kmeans_model = run_mini_batch_kmeans(reduced_embeddings, n_clusters=20)\n",
        "\n",
        "# ---- 6. הצגת תוצאות עם מילים מתויגות ----\n",
        "embedding_df = plot_clusters_with_words(reduced_embeddings, labels, all_tokens)\n"
      ],
      "metadata": {
        "id": "c8np4frBoZYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HDBSCAN"
      ],
      "metadata": {
        "id": "6dXoO3eEwWa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import hdbscan\n",
        "# import torch\n",
        "# import umap\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from adjustText import adjust_text\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# # ---- 1. הפחתת ממדים בעזרת UMAP ----\n",
        "# def reduce_with_umap(all_vectors, n_neighbors=30, min_dist=0.1, n_components=2):\n",
        "#     all_vectors = torch.tensor(all_vectors).to(device)  # Load to GPU if available\n",
        "#     umap_reducer = umap.UMAP(\n",
        "#         n_neighbors=n_neighbors,\n",
        "#         min_dist=min_dist,\n",
        "#         n_components=n_components,\n",
        "#         metric='cosine',\n",
        "#         random_state=42\n",
        "#     )\n",
        "#     reduced_embeddings = umap_reducer.fit_transform(all_vectors.cpu().numpy())\n",
        "#     return reduced_embeddings\n",
        "\n",
        "# # ---- 2. ביצוע HDBSCAN ----\n",
        "# def run_hdbscan(reduced_embeddings, min_cluster_size=30, min_samples=10):\n",
        "#     clusterer = hdbscan.HDBSCAN(\n",
        "#         min_cluster_size=min_cluster_size,\n",
        "#         min_samples=min_samples,\n",
        "#         core_dist_n_jobs=1  # Deactivate parallel processing\n",
        "#     )\n",
        "#     labels = clusterer.fit_predict(reduced_embeddings)\n",
        "#     return labels, clusterer\n",
        "\n",
        "# #\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def plot_clusters_with_words(reduced_embeddings, labels, all_tokens):\n",
        "#     \"\"\"\n",
        "#     Plot clusters with most frequent words only for better efficiency.\n",
        "#     \"\"\"\n",
        "#     # ---- יצירת DataFrame עם האימבדינגס והקלאסטרים ----\n",
        "#     embedding_df = pd.DataFrame({\n",
        "#         'UMAP1': reduced_embeddings[:, 0],\n",
        "#         'UMAP2': reduced_embeddings[:, 1],\n",
        "#         'Token': all_tokens,\n",
        "#         'Cluster': labels\n",
        "#     })\n",
        "\n",
        "#     # ---- חישוב שכיחות מילות מפתח ----\n",
        "#     token_frequency = embedding_df['Token'].value_counts()\n",
        "#     embedding_df['Frequency'] = embedding_df['Token'].map(token_frequency)\n",
        "\n",
        "#     # ---- סינון מילים עם שכיחות גבוהה (מעל סף מסוים) ----\n",
        "#     threshold_frequency = 5  # את יכולה לשנות את המספר הזה כרצונך\n",
        "#     filtered_df = embedding_df[embedding_df['Frequency'] >= threshold_frequency]\n",
        "\n",
        "#     # ---- נירמול התדירות בין 0 ל-1 בשביל צבעים ----\n",
        "#     scaler = MinMaxScaler()\n",
        "#     embedding_df['Frequency_Scaled'] = scaler.fit_transform(embedding_df[['Frequency']])\n",
        "\n",
        "#     # ---- גרף ----\n",
        "#     plt.figure(figsize=(18, 12))\n",
        "#     sns.scatterplot(\n",
        "#         data=embedding_df,\n",
        "#         x='UMAP1',\n",
        "#         y='UMAP2',\n",
        "#         hue='Cluster',\n",
        "#         palette='tab20',\n",
        "#         alpha=0.6,\n",
        "#         legend='full'\n",
        "#     )\n",
        "\n",
        "#     # ---- הוספת שמות של מילים תדירות בלבד ----\n",
        "#     texts = []\n",
        "#     previous_tokens = set()\n",
        "#     for _, row in filtered_df.iterrows():\n",
        "#         token = row['Token']\n",
        "#         if token not in previous_tokens:\n",
        "#             texts.append(plt.text(\n",
        "#                 row['UMAP1'],\n",
        "#                 row['UMAP2'],\n",
        "#                 token,\n",
        "#                 fontsize=min(20, 8 + row['Frequency'] / 2),\n",
        "#                 alpha=0.75\n",
        "#             ))\n",
        "#             previous_tokens.add(token)\n",
        "\n",
        "#     adjust_text(texts)\n",
        "#     plt.title('Clustering with Word Frequency', fontsize=22)\n",
        "#     plt.xlabel('UMAP Dimension 1', fontsize=16)\n",
        "#     plt.ylabel('UMAP Dimension 2', fontsize=16)\n",
        "#     plt.show()\n",
        "\n",
        "#     return embedding_df\n",
        "\n",
        "\n",
        "# # ---- 4. הרצה של HDBSCAN ----\n",
        "\n",
        "# labels, hdbscan_model = run_hdbscan(reduced_embeddings)\n",
        "# embedding_df_hdbscan = plot_clusters_with_words(reduced_embeddings, labels, all_tokens)\n"
      ],
      "metadata": {
        "id": "h294N6j-wXvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GMM (Gaussian Mixture Model)"
      ],
      "metadata": {
        "id": "U8sMNq2dwWsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from adjustText import adjust_text\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---- 1. ביצוע GMM ----\n",
        "def run_gmm(reduced_embeddings, n_components=20):\n",
        "    gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=42)\n",
        "    labels = gmm.fit_predict(reduced_embeddings)\n",
        "    return labels, gmm\n",
        "\n",
        "# ---- 2. גרף עם מילים תדירות ----\n",
        "def plot_gmm_with_words(reduced_embeddings, labels, all_tokens, threshold_frequency=5):\n",
        "    \"\"\"\n",
        "    Plot GMM clusters with most frequent words only for better efficiency.\n",
        "    \"\"\"\n",
        "    # ---- יצירת DataFrame עם האימבדינגס והקלאסטרים ----\n",
        "    embedding_df = pd.DataFrame({\n",
        "        'UMAP1': reduced_embeddings[:, 0],\n",
        "        'UMAP2': reduced_embeddings[:, 1],\n",
        "        'Token': all_tokens,\n",
        "        'Cluster': labels\n",
        "    })\n",
        "\n",
        "    # ---- חישוב שכיחות מילות מפתח ----\n",
        "    token_frequency = embedding_df['Token'].value_counts()\n",
        "    embedding_df['Frequency'] = embedding_df['Token'].map(token_frequency)\n",
        "\n",
        "    # ---- סינון מילים עם שכיחות גבוהה בלבד ----\n",
        "    filtered_df = embedding_df[embedding_df['Frequency'] >= threshold_frequency]\n",
        "\n",
        "    # ---- נירמול התדירות לצבעים ----\n",
        "    scaler = MinMaxScaler()\n",
        "    embedding_df['Frequency_Scaled'] = scaler.fit_transform(embedding_df[['Frequency']])\n",
        "\n",
        "    # ---- גרף ----\n",
        "    plt.figure(figsize=(18, 12))\n",
        "    sns.scatterplot(\n",
        "        data=embedding_df,\n",
        "        x='UMAP1',\n",
        "        y='UMAP2',\n",
        "        hue='Cluster',\n",
        "        palette='tab20',\n",
        "        alpha=0.6,\n",
        "        legend='full'\n",
        "    )\n",
        "\n",
        "    # ---- הוספת שמות מילים שכיחות בלבד ----\n",
        "    texts = []\n",
        "    previous_tokens = set()  # רשימה של מילים שכבר הודפסו כדי למנוע כפילויות\n",
        "    for _, row in filtered_df.iterrows():\n",
        "        token = row['Token']\n",
        "        if token not in previous_tokens:\n",
        "            texts.append(plt.text(\n",
        "                row['UMAP1'],\n",
        "                row['UMAP2'],\n",
        "                token,\n",
        "                fontsize=min(20, 8 + row['Frequency'] / 2),\n",
        "                alpha=0.75\n",
        "            ))\n",
        "            previous_tokens.add(token)\n",
        "\n",
        "    adjust_text(texts)\n",
        "    plt.title('GMM Clustering with Word Frequency', fontsize=22)\n",
        "    plt.xlabel('UMAP Dimension 1', fontsize=16)\n",
        "    plt.ylabel('UMAP Dimension 2', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    return embedding_df\n"
      ],
      "metadata": {
        "id": "nKXI6suVwjz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 3. הרצה של GMM ----\n",
        "labels_gmm, gmm_model = run_gmm(reduced_embeddings)\n",
        "embedding_df_gmm = plot_gmm_with_words(reduced_embeddings, labels_gmm, all_tokens)\n"
      ],
      "metadata": {
        "id": "NenH2Hq1M0Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9WFwb12BM0RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBf2AXaaM0Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# import os\n",
        "\n",
        "# path = \"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data/\"\n",
        "\n",
        "# def save_all_parameters_and_models(\n",
        "#     all_vectors, vector_to_repo, all_tokens, embeddings, best_params=None,\n",
        "#     kmeans_model, hdbscan_model, gmm_model, indexes\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     Save all relevant parameters and models to disk.\n",
        "#     \"\"\"\n",
        "#     if not os.path.exists(path):\n",
        "#         os.makedirs(path)\n",
        "\n",
        "#     # ---- שמירת אינדקסי FAISS ----\n",
        "#     for nlist, index in indexes.items():\n",
        "#         faiss.write_index(index, f\"{path}faiss_index_{nlist}.index\")\n",
        "\n",
        "#     # ---- שמירת כל הנתונים בעזרת פיקל ----\n",
        "#     data = {\n",
        "#         \"vector_to_repo\": vector_to_repo,\n",
        "#         \"all_vectors\": all_vectors,\n",
        "#         \"all_tokens\": all_tokens,\n",
        "#         \"embeddings_name\": embeddings.model.config.name_or_path,\n",
        "#         \"best_params\": best_params,\n",
        "#         \"kmeans_model\": kmeans_model,\n",
        "#         \"hdbscan_model\": hdbscan_model,\n",
        "#         \"gmm_model\": gmm_model\n",
        "#     }\n",
        "\n",
        "#     with open(f\"{path}all_parameters_and_models.pkl\", \"wb\") as f:\n",
        "#         pickle.dump(data, f)\n",
        "\n",
        "#     print(\"All parameters and models saved successfully.\")\n",
        "\n",
        "# # ---- קריאה לפונקציה כדי לשמור הכל ----\n",
        "# save_all_parameters_and_models(\n",
        "#     all_vectors=all_vectors,\n",
        "#     vector_to_repo=vector_to_repo,\n",
        "#     all_tokens=all_tokens,\n",
        "#     embeddings=embeddings,\n",
        "#     best_params=best_params if best_params else None,\n",
        "#     kmeans_model=kmeans_model,\n",
        "#     # hdbscan_model=hdbscan_model,\n",
        "#     gmm_model=gmm_model,\n",
        "#     indexes=indexes\n",
        "# )\n"
      ],
      "metadata": {
        "id": "jLe1jnmuLVKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rkEih-XIthF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nlwjBXUnwWul"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_hD_1lfJCNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CONTINUE"
      ],
      "metadata": {
        "id": "tf4-M6qwJCPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_parameters_and_models(nlist_values):\n",
        "    \"\"\"\n",
        "    Load all relevant parameters and models from disk.\n",
        "    \"\"\"\n",
        "    indexes = {}\n",
        "    for nlist in nlist_values:\n",
        "        index_path = f\"{path}faiss_index_{nlist}.index\"\n",
        "        if os.path.exists(index_path):\n",
        "            index = faiss.read_index(index_path)\n",
        "            indexes[nlist] = index\n",
        "        else:\n",
        "            print(f\"Index file for nlist={nlist} not found at {index_path}.\")\n",
        "\n",
        "    data_path = f\"{path}all_parameters_and_models.pkl\"\n",
        "    if os.path.exists(data_path):\n",
        "        with open(data_path, \"rb\") as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        vector_to_repo = data[\"vector_to_repo\"]\n",
        "        all_vectors = data[\"all_vectors\"]\n",
        "        all_tokens = data[\"all_tokens\"]\n",
        "        embeddings = CustomCodeBERTEmbeddings(model_name=data[\"embeddings_name\"])\n",
        "        best_params = data[\"best_params\"]\n",
        "        kmeans_model = data[\"kmeans_model\"]\n",
        "        hdbscan_model = data[\"hdbscan_model\"]\n",
        "        gmm_model = data[\"gmm_model\"]\n",
        "\n",
        "        print(\"All parameters and models loaded successfully.\")\n",
        "        return indexes, vector_to_repo, all_vectors, all_tokens, embeddings, best_params, kmeans_model, hdbscan_model, gmm_model\n",
        "    else:\n",
        "        print(f\"Precomputed data file not found at {data_path}.\")\n",
        "        return None, None, None, None, None, None, None, None, None\n",
        "\n",
        "\n",
        "loaded_data = load_all_parameters_and_models()\n"
      ],
      "metadata": {
        "id": "CY2QnJ84JCSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Analysis and Visualization\n"
      ],
      "metadata": {
        "id": "aecoGdbp2shd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity(query_vector, all_vectors):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between the query vector and all_vectors.\n",
        "    Returns a list of similarity scores.\n",
        "    \"\"\"\n",
        "    similarities = cosine_similarity(np.array([query_vector]), all_vectors)\n",
        "    return similarities.flatten()\n",
        "\n",
        "\n",
        "\n",
        "def build_ground_truth(queries, embeddings, all_vectors, vector_to_repo, clean_df,\n",
        "                                top_k_percent=0.1, percentile=90, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Build ground truth based on multiple criteria for relevance determination.\n",
        "\n",
        "    Parameters:\n",
        "    - queries: List of query strings.\n",
        "    - embeddings: The embedding model used (CustomCodeBERTEmbeddings).\n",
        "    - all_vectors: The FAISS embeddings for the projects.\n",
        "    - vector_to_repo: Mapping from vector index to repo index.\n",
        "    - clean_df: The DataFrame containing the project metadata.\n",
        "    - top_k_percent: Percentage for Top K% filtering (e.g., 0.1 for Top 10%).\n",
        "    - percentile: Percentile threshold for filtering (e.g., 90 for 90th percentile).\n",
        "    - alpha: Factor for Dynamic Threshold calculation (Mean + alpha * Std).\n",
        "\n",
        "    Returns:\n",
        "    - advanced_ground_truth_df: A DataFrame containing relevant results for each query.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for query in queries:\n",
        "        query_vector = embeddings.embed_query(query)\n",
        "        similarities = calculate_similarity(query_vector, all_vectors)\n",
        "\n",
        "        # Top K% Filtering\n",
        "        top_k_threshold = np.percentile(similarities, 100 - (top_k_percent * 100))\n",
        "        top_k_indices = np.where(similarities >= top_k_threshold)[0]\n",
        "\n",
        "        # Percentile-based Filtering\n",
        "        percentile_threshold = np.percentile(similarities, percentile)\n",
        "        percentile_indices = np.where(similarities >= percentile_threshold)[0]\n",
        "\n",
        "        # Dynamic Threshold Filtering\n",
        "        mean_similarity = np.mean(similarities)\n",
        "        std_similarity = np.std(similarities)\n",
        "        dynamic_threshold = mean_similarity + alpha * std_similarity\n",
        "        dynamic_indices = np.where(similarities >= dynamic_threshold)[0]\n",
        "\n",
        "        # Combine all indices\n",
        "        all_relevant_indices = np.unique(np.concatenate((top_k_indices, percentile_indices, dynamic_indices)))\n",
        "\n",
        "        for idx in all_relevant_indices:\n",
        "            repo_index = vector_to_repo[idx]\n",
        "            repo_name = clean_df.iloc[repo_index][\"Name\"]\n",
        "            repo_url = clean_df.iloc[repo_index][\"URL\"]\n",
        "            repo_topics = clean_df.iloc[repo_index][\"Topics\"]\n",
        "            score = similarities[idx]\n",
        "\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                \"repo_name\": repo_name,\n",
        "                \"repo_url\": repo_url,\n",
        "                \"repo_topics\": repo_topics,\n",
        "                \"score\": score\n",
        "            })\n",
        "\n",
        "    # Create DataFrame for Ground Truth\n",
        "    advanced_ground_truth_df = pd.DataFrame(results)\n",
        "    return advanced_ground_truth_df\n",
        "queries = [\"deep learning\", \"neural networks\", \"python libraries\", \"computer vision\", \"natural language processing\"]\n",
        "\n",
        "ground_truth_df = build_ground_truth(\n",
        "    queries=queries,\n",
        "    embeddings=embeddings,\n",
        "    all_vectors=all_vectors,\n",
        "    vector_to_repo=vector_to_repo,\n",
        "    clean_df=clean_df,\n",
        "    top_k_percent=0.1,\n",
        "    percentile=90,\n",
        "    alpha=0.5\n",
        ")\n",
        "\n",
        "ground_truth_df.head(10)\n",
        "\n"
      ],
      "metadata": {
        "id": "2ROUIhQDHax-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USsp8mkWm0sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_similarity(query_vector, all_vectors):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between the query vector and all_vectors using GPU if available.\n",
        "    \"\"\"\n",
        "    if device == 'cuda':\n",
        "        query_vector = torch.tensor(query_vector).to(device)\n",
        "        all_vectors_gpu = torch.tensor(all_vectors).to(device)\n",
        "        similarities = torch.nn.functional.cosine_similarity(query_vector.unsqueeze(0), all_vectors_gpu)\n",
        "        return similarities.cpu().numpy()\n",
        "    else:\n",
        "        return cosine_similarity(np.array([query_vector]), all_vectors).flatten()\n",
        "\n",
        "\n",
        "def build_ground_truth(queries, embeddings, all_vectors, vector_to_repo, clean_df,\n",
        "                       top_k_percent, percentile, alpha):\n",
        "    \"\"\"\n",
        "    Build ground truth based on multiple criteria for relevance determination.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for query in queries:\n",
        "        query_vector = embeddings.embed_query(query)\n",
        "        similarities = calculate_similarity(query_vector, all_vectors)\n",
        "\n",
        "        # Top K% Filtering\n",
        "        top_k_threshold = np.percentile(similarities, 100 - (top_k_percent * 100))\n",
        "        top_k_indices = np.where(similarities >= top_k_threshold)[0]\n",
        "\n",
        "        # Percentile-based Filtering\n",
        "        percentile_threshold = np.percentile(similarities, percentile)\n",
        "        percentile_indices = np.where(similarities >= percentile_threshold)[0]\n",
        "\n",
        "        # Dynamic Threshold Filtering\n",
        "        mean_similarity = np.mean(similarities)\n",
        "        std_similarity = np.std(similarities)\n",
        "        dynamic_threshold = mean_similarity + alpha * std_similarity\n",
        "        dynamic_indices = np.where(similarities >= dynamic_threshold)[0]\n",
        "\n",
        "        # Combine all indices\n",
        "        all_relevant_indices = np.unique(np.concatenate((top_k_indices, percentile_indices, dynamic_indices)))\n",
        "\n",
        "        for idx in all_relevant_indices:\n",
        "            repo_index = vector_to_repo[idx]\n",
        "            repo_name = clean_df.iloc[repo_index][\"Name\"]\n",
        "            repo_url = clean_df.iloc[repo_index][\"URL\"]\n",
        "            repo_topics = clean_df.iloc[repo_index][\"Topics\"]\n",
        "            score = similarities[idx]\n",
        "\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                \"repo_name\": repo_name,\n",
        "                \"repo_url\": repo_url,\n",
        "                \"repo_topics\": repo_topics,\n",
        "                \"score\": score\n",
        "            })\n",
        "\n",
        "    ground_truth_df = pd.DataFrame(results)\n",
        "    return ground_truth_df\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function to optimize the ground truth generation process.\n",
        "    \"\"\"\n",
        "    top_k_percent = trial.suggest_float(\"top_k_percent\", 0.01, 0.5)  # Between 1% to 50%\n",
        "    percentile = trial.suggest_int(\"percentile\", 80, 99)  # Between 80th to 99th percentile\n",
        "    alpha = trial.suggest_float(\"alpha\", 0.0, 2.0)  # Between 0 and 2 (for dynamic threshold)\n",
        "\n",
        "    # Build the ground truth based on the current hyperparameters\n",
        "    ground_truth_df = build_ground_truth(\n",
        "        queries=queries,\n",
        "        embeddings=embeddings,\n",
        "        all_vectors=all_vectors,\n",
        "        vector_to_repo=vector_to_repo,\n",
        "        clean_df=clean_df,\n",
        "        top_k_percent=top_k_percent,\n",
        "        percentile=percentile,\n",
        "        alpha=alpha\n",
        "    )\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    precision_scores, recall_scores, f1_scores = [], [], []\n",
        "    for query in queries:\n",
        "        relevant_results = ground_truth_df[ground_truth_df['query'] == query]\n",
        "\n",
        "        if relevant_results.empty:\n",
        "            continue\n",
        "\n",
        "        y_true = [1] * len(relevant_results)\n",
        "        y_pred = [1] * len(relevant_results)  # Assuming all found are relevant\n",
        "\n",
        "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Return average F1-score\n",
        "    return np.mean(f1_scores)\n",
        "\n",
        "\n",
        "# ---- הרצה של Optuna ----\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# הצגת התוצאות הטובות ביותר\n",
        "print(\"Best params:\", study.best_params)\n",
        "print(\"Best F1 Score:\", study.best_value)\n"
      ],
      "metadata": {
        "id": "jGUxw4d8QaiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimal Parameters Found by Optuna for Building the Ground Truth  \n",
        "\n",
        "The following parameters were found to be optimal for constructing the ground truth:  \n",
        "\n",
        "- **top_k_percent:** 0.1449 (Top 14.49% of the results).  \n",
        "- **percentile:** 91 (Results in the 91st percentile and above).  \n",
        "- **alpha:** 0.4516 (Affects the Dynamic Threshold).  \n",
        "\n",
        "### Average F1 Score: 1.0  \n",
        "This indicates that the method perfectly identifies all relevant results for the defined queries.  \n",
        "\n",
        "### Conclusion:  \n",
        "The approach of combining three filters (**Top K%**, **Percentiles**, and **Dynamic Threshold**) has proven to be efficient and accurate."
      ],
      "metadata": {
        "id": "s-GI2Zm3WD4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Searching with Optimal Parameters\n",
        "Using the parameters found by Optuna to perform the actual search.\n",
        "\n",
        "Using nlist and nprobe\n",
        "Currently setting nprobe = 10. I will evaluate later if it needs further optimization."
      ],
      "metadata": {
        "id": "Ox12gWZYWxid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def search_with_optimized_params(queries, indexes, vector_to_repo, clean_df, embeddings, top_k=10):\n",
        "    \"\"\"\n",
        "    Perform search using the optimized parameters found with Optuna.\n",
        "\n",
        "    Parameters:\n",
        "    - queries: List of search queries.\n",
        "    - indexes: Dictionary of FAISS indexes (key: nlist, value: index object).\n",
        "    - vector_to_repo: Mapping from vector index to repo index.\n",
        "    - clean_df: DataFrame containing repository information.\n",
        "    - embeddings: The embedding model to convert queries to vectors.\n",
        "    - top_k: Number of top results to retrieve per query.\n",
        "\n",
        "    Returns:\n",
        "    - results_df: DataFrame containing search results.\n",
        "    \"\"\"\n",
        "    results_summary = []\n",
        "\n",
        "    for nlist, index in indexes.items():\n",
        "        index.nprobe = 10  # Using a fixed nprobe for now, we can optimize this later\n",
        "\n",
        "        for query in tqdm(queries, desc=f\"Searching with nlist={nlist}\"):\n",
        "            query_vector = embeddings.embed_query(query)\n",
        "            distances, indices = index.search(np.array([query_vector], dtype='float32'), top_k)\n",
        "\n",
        "            for i, idx in enumerate(indices[0]):\n",
        "                if idx == -1:\n",
        "                    continue\n",
        "\n",
        "                repo_index = vector_to_repo[idx]\n",
        "                repo_name = clean_df.iloc[repo_index][\"Name\"]\n",
        "                repo_url = clean_df.iloc[repo_index][\"URL\"]\n",
        "                repo_topics = clean_df.iloc[repo_index][\"Topics\"]\n",
        "                score = distances[0][i]\n",
        "\n",
        "                results_summary.append({\n",
        "                    \"query\": query,\n",
        "                    \"nlist\": nlist,\n",
        "                    \"repo_name\": repo_name,\n",
        "                    \"repo_url\": repo_url,\n",
        "                    \"repo_topics\": repo_topics,\n",
        "                    \"score\": score\n",
        "                })\n",
        "\n",
        "    # Create DataFrame with the search results\n",
        "    results_df = pd.DataFrame(results_summary)\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# ---- חיפוש בעזרת הפרמטרים האופטימליים ----\n",
        "optimized_results_df = search_with_optimized_params(\n",
        "    queries=queries,\n",
        "    indexes=indexes,\n",
        "    vector_to_repo=vector_to_repo,\n",
        "    clean_df=clean_df,\n",
        "    embeddings=embeddings,\n",
        "    top_k=10\n",
        ")\n",
        "\n",
        "# הצגת תוצאות החיפוש\n",
        "optimized_results_df.head(10)\n"
      ],
      "metadata": {
        "id": "TQuZYuTo7Lch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "#### Building Ground Truth  \n",
        "Checking which projects are relevant to the queries according to **ground_truth_df** created using **Optuna**.  \n",
        "\n",
        "#### FAISS Search Results  \n",
        "Comparing the projects retrieved by **FAISS** against the **Ground Truth**.  \n",
        "\n",
        "#### Metrics Calculation  \n",
        "Calculating **Precision**, **Recall**, and **F1-Score** for each query separately.  \n",
        "\n",
        "#### Displaying Results  \n",
        "The results are presented in a table, showing for each query how accurately **FAISS** identifies the relevant projects."
      ],
      "metadata": {
        "id": "9L3SJYwlWWMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_search_results(optimized_results_df, ground_truth_df):\n",
        "    \"\"\"\n",
        "    Compare search results from FAISS with the ground truth and calculate metrics.\n",
        "\n",
        "    Parameters:\n",
        "    - optimized_results_df: DataFrame containing search results from FAISS.\n",
        "    - ground_truth_df: DataFrame containing the ground truth results.\n",
        "\n",
        "    Returns:\n",
        "    - metrics_df: DataFrame containing precision, recall, and f1-score for each query.\n",
        "    \"\"\"\n",
        "    precision_list, recall_list, f1_list = [],[],[]\n",
        "    queries = optimized_results_df['query'].unique()\n",
        "\n",
        "    for query in queries:\n",
        "        # Get the relevant projects according to ground truth\n",
        "        relevant_projects = set(ground_truth_df[ground_truth_df['query'] == query]['repo_name'])\n",
        "\n",
        "        # Get the projects retrieved by FAISS\n",
        "        retrieved_projects = set(optimized_results_df[optimized_results_df['query'] == query]['repo_name'])\n",
        "\n",
        "        # Create binary labels\n",
        "        y_true = [1 if project in relevant_projects else 0 for project in retrieved_projects]\n",
        "        y_pred = [1] * len(retrieved_projects)\n",
        "\n",
        "        # Calculate metrics\n",
        "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "        # Store results\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "    # Create DataFrame to display results\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'query': queries,\n",
        "        'precision': precision_list,\n",
        "        'recall': recall_list,\n",
        "        'f1': f1_list\n",
        "    })\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "\n",
        "metrics_df = evaluate_search_results(optimized_results_df, ground_truth_df)"
      ],
      "metadata": {
        "id": "u28HIQer8lIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df"
      ],
      "metadata": {
        "id": "gQJ04QvwWjoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "top_k_percent = best_params[\"top_k_percent\"]\n",
        "percentile = best_params[\"percentile\"]\n",
        "alpha = best_params[\"alpha\"]\n"
      ],
      "metadata": {
        "id": "YTSavlEMuCzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ---- 1. דגימה של תתי-וקטורים ----\n",
        "sample_size = 5000\n",
        "sample_indices = random.sample(range(len(all_vectors)), min(sample_size, len(all_vectors)))\n",
        "sampled_vectors = [all_vectors[i] for i in sample_indices]\n",
        "sampled_tokens = [all_tokens[i] for i in sample_indices]\n",
        "\n",
        "# ---- 2. הפחתת ממדים בעזרת UMAP ----\n",
        "umap_reducer = umap.UMAP(\n",
        "    n_neighbors=int(30 * top_k_percent),  # התאמת הפרמטר top_k_percent\n",
        "    n_components=2,\n",
        "    metric='cosine',\n",
        "    random_state=42,\n",
        "    min_dist=0.1\n",
        ")\n",
        "reduced_embeddings = umap_reducer.fit_transform(sampled_vectors)\n",
        "\n",
        "# ---- 3. הכנת הנתונים להצגה ----\n",
        "embedding_df = pd.DataFrame({\n",
        "    'UMAP1': reduced_embeddings[:, 0],\n",
        "    'UMAP2': reduced_embeddings[:, 1],\n",
        "    'Token': sampled_tokens\n",
        "})\n",
        "\n",
        "# ---- 4. חישוב תדירות מילות מפתח ----\n",
        "token_frequency = embedding_df['Token'].value_counts()\n",
        "embedding_df['Frequency'] = embedding_df['Token'].map(token_frequency)\n",
        "\n",
        "# ---- 5. סינון מונחים לפי שכיחותם ----\n",
        "threshold_frequency = 5  # הצגת מונחים שמופיעים לפחות מספר פעמים זה\n",
        "filtered_df = embedding_df[embedding_df['Frequency'] >= threshold_frequency]\n",
        "\n",
        "# ---- 6. נירמול התדירות בין 0 ל-1 ----\n",
        "scaler = MinMaxScaler()\n",
        "embedding_df['Frequency_Scaled'] = scaler.fit_transform(embedding_df[['Frequency']])\n",
        "\n",
        "# ---- 7. הגדרות גרף ----\n",
        "plt.figure(figsize=(18, 12))  # גודל גרף מותאם\n",
        "\n",
        "# הגדרת הגרף עם ax\n",
        "ax = sns.scatterplot(\n",
        "    x='UMAP1',\n",
        "    y='UMAP2',\n",
        "    hue='Frequency_Scaled',\n",
        "    palette='cool',\n",
        "    data=embedding_df,\n",
        "    s=80,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "# הצגת מפת צבעים\n",
        "norm = plt.Normalize(embedding_df['Frequency_Scaled'].min(), embedding_df['Frequency_Scaled'].max())\n",
        "sm = plt.cm.ScalarMappable(cmap='cool', norm=norm)\n",
        "sm.set_array([])\n",
        "plt.colorbar(sm, ax=ax, label='Token Frequency (Scaled)', orientation='vertical')\n",
        "\n",
        "# ---- 8. הוספת שמות המילים ----\n",
        "previous_tokens = set()  # רשימה לשמירה על המילים שכבר הוצגו\n",
        "texts = []  # רשימה של הטקסטים שמוסיפים לגרף\n",
        "for i, row in filtered_df.iterrows():\n",
        "    x, y = row['UMAP1'], row['UMAP2']\n",
        "    token = row['Token']\n",
        "\n",
        "    if token not in previous_tokens:\n",
        "        texts.append(plt.text(\n",
        "            x,\n",
        "            y,\n",
        "            token,\n",
        "            fontsize=min(20, 8 + row['Frequency'] / 2),\n",
        "            alpha=0.9,\n",
        "            weight='bold' if row['Frequency'] > 50 else 'normal'\n",
        "        ))\n",
        "        previous_tokens.add(token)\n",
        "\n",
        "# התאמת המילים מבלי לחפוף אחת על השנייה\n",
        "adjust_text(texts)\n",
        "\n",
        "plt.title('Visualization of Tokens in Semantic Space (UMAP)', fontsize=26)\n",
        "plt.xlabel('UMAP Dimension 1', fontsize=20)\n",
        "plt.ylabel('UMAP Dimension 2', fontsize=20)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Gyn5Zfjv1IST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "def save_precomputed_data(indexes, vector_to_repo, all_vectors, all_tokens, embeddings, best_params):\n",
        "    \"\"\"\n",
        "    Save the relevant precomputed data to disk.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data\"):\n",
        "        os.makedirs(\"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data\")\n",
        "\n",
        "    # Save FAISS indexes\n",
        "    for nlist, index in indexes.items():\n",
        "        faiss.write_index(index, f\"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data/faiss_index_{nlist}.index\")\n",
        "\n",
        "    # Save other data with pickle\n",
        "    data = {\n",
        "        \"vector_to_repo\": vector_to_repo,\n",
        "        \"all_vectors\": all_vectors,\n",
        "        \"all_tokens\": all_tokens,\n",
        "        \"embeddings_name\": embeddings.model.config.name_or_path,  # Save model name instead of the object\n",
        "        \"best_params\": best_params  # Save the best parameters found by Optuna\n",
        "    }\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data/precomputed_data.pkl\", \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "\n",
        "\n",
        "save_precomputed_data(indexes, vector_to_repo, all_vectors, all_tokens, embeddings, best_params)\n",
        "indexes, vector_to_repo, all_vectors, all_tokens, embeddings, best_params = load_precomputed_data(nlist_values)\n"
      ],
      "metadata": {
        "id": "K7VL916q1tGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--N5JmrP2aGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "qJbmsmc063e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6sVQ90iT_LeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results Analysis  \n",
        "#### Precision:  \n",
        "The results are very high (between **0.65 and 0.85**) – meaning most of the results retrieved by the system are relevant to the query.  \n",
        "\n",
        "#### Recall:  \n",
        "The results are **1.0** for all queries.  \n",
        "This means all relevant projects in the **Ground Truth** were successfully found by the system, which is excellent.  \n",
        "\n",
        "#### F1 Score:  \n",
        "The scores are very high (between **0.79 and 0.92**).  \n",
        "This shows an excellent balance between **Precision** and **Complete Retrieval (Recall)**."
      ],
      "metadata": {
        "id": "0fQIN8WYXDkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Pipeline using LangChain"
      ],
      "metadata": {
        "id": "0IfmLTajXLuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def load_precomputed_data(nlist_values):\n",
        "    \"\"\"\n",
        "    Load the saved precomputed data from disk.\n",
        "    \"\"\"\n",
        "    indexes = {}\n",
        "\n",
        "    # Load FAISS indexes\n",
        "    for nlist in nlist_values:\n",
        "        index_path = f\"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data/faiss_index_{nlist}.index\"\n",
        "        if os.path.exists(index_path):\n",
        "            index = faiss.read_index(index_path)\n",
        "            indexes[nlist] = index\n",
        "        else:\n",
        "            print(f\"Index file for nlist={nlist} not found at {index_path}.\")\n",
        "\n",
        "    # Load other data\n",
        "    data_path = \"/content/drive/MyDrive/GitHubRepositoriesProject/saved_data/precomputed_data.pkl\"\n",
        "    if os.path.exists(data_path):\n",
        "        with open(data_path, \"rb\") as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        vector_to_repo = data[\"vector_to_repo\"]\n",
        "        all_vectors = data[\"all_vectors\"]\n",
        "        all_tokens = data[\"all_tokens\"]\n",
        "        embeddings = CustomCodeBERTEmbeddings(model_name=data[\"embeddings_name\"])  # Reinitialize the embeddings object\n",
        "        best_params = data[\"best_params\"]\n",
        "\n",
        "        return indexes, vector_to_repo, all_vectors, all_tokens, embeddings, best_params\n",
        "    else:\n",
        "        print(f\"Precomputed data file not found at {data_path}.\")\n",
        "        return None, None, None, None, None, None"
      ],
      "metadata": {
        "id": "R72RkWpC_Kdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlist_values = [100, 200, 300, 500]\n",
        "\n",
        "indexes, vector_to_repo, all_vectors, all_tokens, embeddings, best_params = load_precomputed_data(nlist_values)"
      ],
      "metadata": {
        "id": "EFWK4rzv_M-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2-CQAcqk--4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Improved RAG Pipeline ---\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from langchain.vectorstores import FAISS\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from langchain_openai import OpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('open_ai_key')\n",
        "\n",
        "# ---- יצירת אובייקט ה-LLM ----\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# class CustomCodeBERTEmbeddings(Embeddings):\n",
        "#     def __init__(self, model_name=\"microsoft/codebert-base\"):\n",
        "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#         self.model = AutoModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "#     def embed_documents(self, texts, batch_size=64):\n",
        "#         embeddings = []\n",
        "#         for i in range(0, len(texts), batch_size):\n",
        "#             batch = texts[i:i + batch_size]\n",
        "#             inputs = self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#             with torch.no_grad():\n",
        "#                 outputs = self.model(**inputs)\n",
        "#             batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "#             embeddings.extend(batch_embeddings)\n",
        "#         return np.array(embeddings)\n",
        "\n",
        "#     def embed_query(self, query):\n",
        "#         return self.embed_documents([query])[0]\n",
        "\n",
        "\n",
        "embeddings = CustomCodeBERTEmbeddings()\n",
        "\n",
        "\n",
        "def search_in_index(query, index, top_k=5, nprobe=10):\n",
        "    index.nprobe = nprobe\n",
        "    query_vector = embeddings.embed_query(query)\n",
        "    distances, indices = index.search(np.array([query_vector], dtype='float32'), top_k)\n",
        "    results = []\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        if idx == -1: continue\n",
        "        repo_index = vector_to_repo[idx]\n",
        "        repo_name = clean_df.iloc[repo_index]['Name']\n",
        "        repo_description = clean_df.iloc[repo_index]['Description']\n",
        "        repo_url = clean_df.iloc[repo_index]['URL']\n",
        "        repo_topics = clean_df.iloc[repo_index]['Topics']\n",
        "        score = distances[0][i]\n",
        "        results.append({\n",
        "            'name': repo_name,\n",
        "            'description': repo_description,\n",
        "            'url': repo_url,\n",
        "            'topics': repo_topics,\n",
        "            'score': score\n",
        "        })\n",
        "    return results\n",
        "\n",
        "best_nlist = 100\n",
        "index = indexes[best_nlist]\n",
        "\n",
        "def generate_answer_with_rag(query, top_k=5):\n",
        "    search_results = search_in_index(query, index, top_k)\n",
        "    if not search_results:\n",
        "        return \"No relevant repositories found.\"\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are an expert in providing structured answers based on relevant GitHub repositories.\\n\"\n",
        "        f\"Provide a well-organized response for the query: '{query}'.\\n\\n\"\n",
        "        \"### Relevant Repositories:###\\n\"\n",
        "    )\n",
        "    for result in search_results:\n",
        "        prompt += (\n",
        "            f\" - Description: {result['description']}\\n\"\n",
        "            f\"- Repository: {result['name']}\\n\"\n",
        "            f\"  - Topics: {result['topics']}\\n\"\n",
        "            f\"  - URL: {result['url']}\\n\"\n",
        "            f\"  - Relevance Score: {result['score']}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    response = llm(prompt)\n",
        "    return response\n",
        "\n"
      ],
      "metadata": {
        "id": "LfHIa4bSy9M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example Usage\n",
        "query = \"How to build deep learning models with PyTorch?\"\n",
        "answer = generate_answer_with_rag(query, top_k=5)\n"
      ],
      "metadata": {
        "id": "g0HtTSuLzBjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer.content)\n"
      ],
      "metadata": {
        "id": "d0SL_Zk1zSwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG evaluation"
      ],
      "metadata": {
        "id": "98IIWAaWEVpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install rouge_score"
      ],
      "metadata": {
        "id": "OFjQnzcYEGtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_search_results(optimized_results_df, ground_truth_df):\n",
        "    \"\"\"\n",
        "    Compare search results with the ground truth and calculate metrics (Precision, Recall, F1, ROUGE, BLEU, MRR).\n",
        "    \"\"\"\n",
        "    precision_list, recall_list, f1_list = [], [], []\n",
        "    rouge_scores, bleu_scores, mrr_scores = [], [], []\n",
        "    queries = optimized_results_df['query'].unique()\n",
        "\n",
        "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    for query in tqdm(queries, desc=\"Evaluating Queries\"):\n",
        "        relevant_projects = set(ground_truth_df[ground_truth_df['query'] == query]['repo_name'])\n",
        "        retrieved_projects = optimized_results_df[optimized_results_df['query'] == query]['repo_name'].tolist()\n",
        "\n",
        "        # Calculate Precision, Recall, F1\n",
        "        y_true = [1 if project in relevant_projects else 0 for project in retrieved_projects]\n",
        "        y_pred = [1] * len(retrieved_projects)\n",
        "\n",
        "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "        # Calculate ROUGE & BLEU for each query\n",
        "        relevant_texts = ground_truth_df[ground_truth_df['query'] == query]['repo_topics'].tolist()\n",
        "        retrieved_texts = optimized_results_df[optimized_results_df['query'] == query]['repo_topics'].tolist()\n",
        "\n",
        "        if retrieved_texts and relevant_texts:\n",
        "            # ROUGE Score Calculation\n",
        "            rouge_scores_per_query = []\n",
        "            for retrieved_text in retrieved_texts:\n",
        "                score = rouge_scorer_obj.score(relevant_texts[0], retrieved_text)\n",
        "                rouge_scores_per_query.append(score['rougeL'].fmeasure)\n",
        "\n",
        "            # BLEU Score Calculation (Taking average of top 5 results)\n",
        "            bleu_scores_per_query = [sentence_bleu([relevant_texts[0].split()], retrieved_text.split()) for retrieved_text in retrieved_texts[:5]]\n",
        "\n",
        "            rouge_scores.append(np.mean(rouge_scores_per_query))\n",
        "            bleu_scores.append(np.mean(bleu_scores_per_query))\n",
        "\n",
        "            # MRR Calculation\n",
        "            rank = 0\n",
        "            for i, retrieved_project in enumerate(retrieved_projects):\n",
        "                if retrieved_project in relevant_projects:\n",
        "                    rank = i + 1\n",
        "                    break\n",
        "            if rank > 0:\n",
        "                mrr_scores.append(1 / rank)\n",
        "            else:\n",
        "                mrr_scores.append(0)\n",
        "        else:\n",
        "            rouge_scores.append(0)\n",
        "            bleu_scores.append(0)\n",
        "            mrr_scores.append(0)\n",
        "\n",
        "    # Create Evaluation DataFrame\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'query': queries,\n",
        "        'precision': precision_list,\n",
        "        'recall': recall_list,\n",
        "        'f1': f1_list,\n",
        "        'ROUGE': rouge_scores,\n",
        "        'BLEU': bleu_scores,\n",
        "        'MRR': mrr_scores\n",
        "    })\n",
        "\n",
        "    # Displaying the results\n",
        "\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "metrics_df = evaluate_search_results(optimized_results_df, ground_truth_df)\n"
      ],
      "metadata": {
        "id": "rm_QuABQwGMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df"
      ],
      "metadata": {
        "id": "dHIjISFUERWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}